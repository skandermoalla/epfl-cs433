{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_cost` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss by MSE\n",
    "    # ***************************************************\n",
    "    e = y - tx @ w\n",
    "    return e.T.dot(e) / (2 * y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694.483365887085"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(y, tx, np.array([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "        \n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss for each combination of w0 and w1.\n",
    "    # ***************************************************\n",
    "    for i, w0 in enumerate(grid_w0):\n",
    "        for j, w1 in enumerate(grid_w1):\n",
    "            losses[i,j] = compute_loss(y, tx, np.array([w0, w1]))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=15.610085652488799, w0*=73.36683417085428, w1*=12.8140703517588, execution time=2.801 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=200)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "      l=loss_star, w0=w0_star, w1=w1_star, t=execution_time))\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0,6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute gradient vector\n",
    "    # ***************************************************\n",
    "    e = y - tx @ w\n",
    "    return - tx.T.dot(e) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([26.706078  ,  6.52028757]), array([-3.293922  , -1.47971243])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[compute_gradient(y, tx, w) for w in [np.array([100,20]), np.array([70,12])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD \n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        grad_w = compute_gradient(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "        w -= gamma * grad_w\n",
    "        \n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=1062606.4462798769, w0=-463.3530389989468, w1=506.73985621749387\n",
      "GD iter. 1/49: loss=265663.1509858701, w0=-195.02955849842033, w1=260.1097843262411\n",
      "GD iter. 2/49: loss=66427.32716236892, w0=-60.86781824815742, w1=136.79474838061495\n",
      "GD iter. 3/49: loss=16618.37120649382, w0=6.213051876973964, w1=75.13723040780187\n",
      "GD iter. 4/49: loss=4166.132217525063, w0=39.75348693953961, w1=44.308471421395396\n",
      "GD iter. 5/49: loss=1053.072470282885, w0=56.52370447082242, w1=28.894091928192196\n",
      "GD iter. 6/49: loss=274.8075334723426, w0=64.90881323646381, w1=21.18690218159061\n",
      "GD iter. 7/49: loss=80.2412992697075, w0=69.1013676192845, w1=17.33330730828982\n",
      "GD iter. 8/49: loss=31.5997407190489, w0=71.19764481069485, w1=15.406509871639432\n",
      "GD iter. 9/49: loss=19.439351081384252, w0=72.24578340640002, w1=14.44311115331424\n",
      "GD iter. 10/49: loss=16.39925367196811, w0=72.7698527042526, w1=13.961411794151644\n",
      "GD iter. 11/49: loss=15.639229319614081, w0=73.03188735317889, w1=13.720562114570345\n",
      "GD iter. 12/49: loss=15.449223231525577, w0=73.16290467764203, w1=13.600137274779696\n",
      "GD iter. 13/49: loss=15.401721709503438, w0=73.22841333987361, w1=13.539924854884372\n",
      "GD iter. 14/49: loss=15.389846328997908, w0=73.2611676709894, w1=13.509818644936711\n",
      "GD iter. 15/49: loss=15.386877483871539, w0=73.27754483654729, w1=13.49476553996288\n",
      "GD iter. 16/49: loss=15.38613527258993, w0=73.28573341932623, w1=13.487238987475966\n",
      "GD iter. 17/49: loss=15.385949719769528, w0=73.28982771071571, w1=13.483475711232508\n",
      "GD iter. 18/49: loss=15.385903331564434, w0=73.29187485641044, w1=13.481594073110779\n",
      "GD iter. 19/49: loss=15.385891734513157, w0=73.29289842925782, w1=13.480653254049914\n",
      "GD iter. 20/49: loss=15.385888835250341, w0=73.2934102156815, w1=13.480182844519481\n",
      "GD iter. 21/49: loss=15.385888110434646, w0=73.29366610889335, w1=13.479947639754265\n",
      "GD iter. 22/49: loss=15.385887929230716, w0=73.29379405549926, w1=13.479830037371658\n",
      "GD iter. 23/49: loss=15.385887883929728, w0=73.29385802880222, w1=13.479771236180353\n",
      "GD iter. 24/49: loss=15.385887872604478, w0=73.29389001545371, w1=13.4797418355847\n",
      "GD iter. 25/49: loss=15.385887869773173, w0=73.29390600877944, w1=13.479727135286875\n",
      "GD iter. 26/49: loss=15.385887869065343, w0=73.29391400544232, w1=13.479719785137963\n",
      "GD iter. 27/49: loss=15.385887868888378, w0=73.29391800377375, w1=13.479716110063507\n",
      "GD iter. 28/49: loss=15.385887868844144, w0=73.29392000293947, w1=13.479714272526278\n",
      "GD iter. 29/49: loss=15.385887868833091, w0=73.29392100252232, w1=13.479713353757663\n",
      "GD iter. 30/49: loss=15.385887868830325, w0=73.29392150231375, w1=13.479712894373357\n",
      "GD iter. 31/49: loss=15.385887868829617, w0=73.29392175220947, w1=13.479712664681204\n",
      "GD iter. 32/49: loss=15.385887868829453, w0=73.29392187715733, w1=13.479712549835126\n",
      "GD iter. 33/49: loss=15.385887868829414, w0=73.29392193963126, w1=13.479712492412087\n",
      "GD iter. 34/49: loss=15.385887868829407, w0=73.29392197086823, w1=13.479712463700569\n",
      "GD iter. 35/49: loss=15.385887868829398, w0=73.29392198648671, w1=13.47971244934481\n",
      "GD iter. 36/49: loss=15.385887868829403, w0=73.29392199429594, w1=13.47971244216693\n",
      "GD iter. 37/49: loss=15.385887868829407, w0=73.29392199820056, w1=13.47971243857799\n",
      "GD iter. 38/49: loss=15.3858878688294, w0=73.29392200015288, w1=13.479712436783519\n",
      "GD iter. 39/49: loss=15.3858878688294, w0=73.29392200112903, w1=13.479712435886285\n",
      "GD iter. 40/49: loss=15.385887868829407, w0=73.2939220016171, w1=13.479712435437667\n",
      "GD iter. 41/49: loss=15.385887868829403, w0=73.29392200186115, w1=13.479712435213358\n",
      "GD iter. 42/49: loss=15.385887868829403, w0=73.29392200198316, w1=13.479712435101204\n",
      "GD iter. 43/49: loss=15.385887868829398, w0=73.29392200204417, w1=13.479712435045126\n",
      "GD iter. 44/49: loss=15.385887868829409, w0=73.29392200207468, w1=13.479712435017088\n",
      "GD iter. 45/49: loss=15.385887868829407, w0=73.29392200208993, w1=13.47971243500307\n",
      "GD iter. 46/49: loss=15.385887868829398, w0=73.29392200209756, w1=13.47971243499606\n",
      "GD iter. 47/49: loss=15.3858878688294, w0=73.29392200210137, w1=13.479712434992555\n",
      "GD iter. 48/49: loss=15.385887868829407, w0=73.29392200210327, w1=13.479712434990802\n",
      "GD iter. 49/49: loss=15.3858878688294, w0=73.29392200210422, w1=13.479712434989926\n",
      "GD: execution time=0.022 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.5\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([-1000, 1000.])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f78afbd7578492d953cee59b6844f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses, gd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from just few examples n and their corresponding y_n labels.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    # ***************************************************\n",
    "    return compute_gradient(y, tx, w)\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "            \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size=batch_size, num_batches=1):\n",
    "            # compute a stochastic gradient and loss\n",
    "            grad, = compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "            # update w through the stochastic gradient update\n",
    "            w = w - gamma * grad\n",
    "            # calculate loss\n",
    "            loss = compute_loss(y, tx, w)\n",
    "            # store w and loss\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "        print(\"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2330.5865200388002, w0=5.693771233442, w1=5.693771233442\n",
      "SGD iter. 1/49: loss=1873.4285316567345, w0=12.34478559603274, w1=12.34478559603274\n",
      "SGD iter. 2/49: loss=1522.5644263679608, w0=18.633158459397826, w1=18.633158459397826\n",
      "SGD iter. 3/49: loss=1307.2102317560425, w0=23.452188369419005, w1=23.452188369419005\n",
      "SGD iter. 4/49: loss=1055.286841327161, w0=31.32588703370615, w1=31.32588703370615\n",
      "SGD iter. 5/49: loss=1061.2999803794376, w0=31.079129540681492, w1=31.079129540681492\n",
      "SGD iter. 6/49: loss=993.9196886619842, w0=34.21627283675429, w1=34.21627283675429\n",
      "SGD iter. 7/49: loss=917.9161184089105, w0=40.54159068883836, w1=40.54159068883836\n",
      "SGD iter. 8/49: loss=920.5133722752013, w0=46.65676643400124, w1=46.65676643400124\n",
      "SGD iter. 9/49: loss=959.5792030748773, w0=50.44078054928006, w1=50.44078054928006\n",
      "SGD iter. 10/49: loss=959.8185842848047, w0=50.45772804256777, w1=50.45772804256777\n",
      "SGD iter. 11/49: loss=912.3535531100445, w0=44.97827840453069, w1=44.97827840453069\n",
      "SGD iter. 12/49: loss=926.4835037420604, w0=47.46881419778512, w1=47.46881419778512\n",
      "SGD iter. 13/49: loss=934.7339435943381, w0=48.37812357968998, w1=48.37812357968998\n",
      "SGD iter. 14/49: loss=962.0626262409628, w0=50.6146676484751, w1=50.6146676484751\n",
      "SGD iter. 15/49: loss=966.6361056376747, w0=50.9244097542393, w1=50.9244097542393\n",
      "SGD iter. 16/49: loss=913.492978527011, w0=45.30310898220376, w1=45.30310898220376\n",
      "SGD iter. 17/49: loss=927.078824196827, w0=47.54109450747168, w1=47.54109450747168\n",
      "SGD iter. 18/49: loss=980.0432710107218, w0=51.76670186018564, w1=51.76670186018564\n",
      "SGD iter. 19/49: loss=1068.2996253010378, w0=55.97565437284717, w1=55.97565437284717\n",
      "SGD iter. 20/49: loss=1150.500261387419, w0=58.900664484259984, w1=58.900664484259984\n",
      "SGD iter. 21/49: loss=1141.9138223504676, w0=58.62141658797312, w1=58.62141658797312\n",
      "SGD iter. 22/49: loss=1427.2331578152025, w0=66.13351705416395, w1=66.13351705416395\n",
      "SGD iter. 23/49: loss=1206.3331337703835, w0=60.60635058524525, w1=60.60635058524525\n",
      "SGD iter. 24/49: loss=1264.1576904544074, w0=62.21065545762192, w1=62.21065545762192\n",
      "SGD iter. 25/49: loss=1194.2161107321756, w0=60.250841243927994, w1=60.250841243927994\n",
      "SGD iter. 26/49: loss=1185.517294850697, w0=59.99092786763473, w1=59.99092786763473\n",
      "SGD iter. 27/49: loss=1238.0486835409383, w0=61.50387766270821, w1=61.50387766270821\n",
      "SGD iter. 28/49: loss=1677.3934250777695, w0=71.0919182050842, w1=71.0919182050842\n",
      "SGD iter. 29/49: loss=2332.470871233547, w0=81.1048509269736, w1=81.1048509269736\n",
      "SGD iter. 30/49: loss=1750.4871038580611, w0=72.38106319002412, w1=72.38106319002412\n",
      "SGD iter. 31/49: loss=1406.2846646385744, w0=65.66828620591467, w1=65.66828620591467\n",
      "SGD iter. 32/49: loss=1490.3311072562694, w0=67.48059863310962, w1=67.48059863310962\n",
      "SGD iter. 33/49: loss=1283.2545850421611, w0=62.711252026287525, w1=62.711252026287525\n",
      "SGD iter. 34/49: loss=1151.8331773520385, w0=58.9435640811944, w1=58.9435640811944\n",
      "SGD iter. 35/49: loss=1032.5723803262117, w0=54.46614824179303, w1=54.46614824179303\n",
      "SGD iter. 36/49: loss=1331.188807346022, w0=63.914067471381024, w1=63.914067471381024\n",
      "SGD iter. 37/49: loss=1422.783925988746, w0=66.0355063988329, w1=66.0355063988329\n",
      "SGD iter. 38/49: loss=1528.127771119912, w0=68.2525962474929, w1=68.2525962474929\n",
      "SGD iter. 39/49: loss=2100.984976953285, w0=77.90006355310297, w1=77.90006355310297\n",
      "SGD iter. 40/49: loss=2502.8274485911725, w0=83.29930454003112, w1=83.29930454003112\n",
      "SGD iter. 41/49: loss=1624.9867255425452, w0=70.129403502207, w1=70.129403502207\n",
      "SGD iter. 42/49: loss=2353.3395689512813, w0=81.38048464547143, w1=81.38048464547143\n",
      "SGD iter. 43/49: loss=2761.003994377937, w0=86.41219565935094, w1=86.41219565935094\n",
      "SGD iter. 44/49: loss=3432.4861279765732, w0=93.61295905298452, w1=93.61295905298452\n",
      "SGD iter. 45/49: loss=4296.556201373188, w0=101.58248197950365, w1=101.58248197950365\n",
      "SGD iter. 46/49: loss=2897.434930690087, w0=87.96948342736124, w1=87.96948342736124\n",
      "SGD iter. 47/49: loss=2432.1641498788454, w0=82.40403579541768, w1=82.40403579541768\n",
      "SGD iter. 48/49: loss=1883.0936183826532, w0=74.58413784034254, w1=74.58413784034254\n",
      "SGD iter. 49/49: loss=1480.2380373568044, w0=67.2702263753918, w1=67.2702263753918\n",
      "SGD: execution time=0.015 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996193a7ffd9487c92679aba1ad97152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses, sgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200, 2))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11f27e8f0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(height, weight, marker=\".\", color='b', s=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2829.2722244384163, w0=51.54259072181176, w1=10.132993413506084\n",
      "GD iter. 1/49: loss=267.05002587794297, w0=67.0053679383553, w1=13.172891437557826\n",
      "GD iter. 2/49: loss=36.45002800750046, w0=71.64420110331837, w1=14.084860844773324\n",
      "GD iter. 3/49: loss=15.696028199160661, w0=73.03585105280729, w1=14.358451666937965\n",
      "GD iter. 4/49: loss=13.828168216410079, w0=73.45334603765397, w1=14.440528913587356\n",
      "GD iter. 5/49: loss=13.660060817962522, w0=73.57859453310797, w1=14.46515208758217\n",
      "GD iter. 6/49: loss=13.644931152102242, w0=73.61616908174418, w1=14.472539039780616\n",
      "GD iter. 7/49: loss=13.643569482174815, w0=73.62744144633503, w1=14.474755125440149\n",
      "GD iter. 8/49: loss=13.643446931881352, w0=73.63082315571229, w1=14.47541995113801\n",
      "GD iter. 9/49: loss=13.643435902354934, w0=73.63183766852546, w1=14.475619398847368\n",
      "GD iter. 10/49: loss=13.643434909697557, w0=73.63214202236942, w1=14.475679233160175\n",
      "GD iter. 11/49: loss=13.643434820358395, w0=73.6322333285226, w1=14.475697183454017\n",
      "GD iter. 12/49: loss=13.643434812317876, w0=73.63226072036856, w1=14.47570256854217\n",
      "GD iter. 13/49: loss=13.643434811594226, w0=73.63226893792235, w1=14.475704184068615\n",
      "GD iter. 14/49: loss=13.643434811529096, w0=73.63227140318848, w1=14.475704668726548\n",
      "GD iter. 15/49: loss=13.643434811523234, w0=73.63227214276833, w1=14.47570481412393\n",
      "GD iter. 16/49: loss=13.643434811522706, w0=73.63227236464228, w1=14.475704857743143\n",
      "GD iter. 17/49: loss=13.64343481152266, w0=73.63227243120447, w1=14.475704870828908\n",
      "GD iter. 18/49: loss=13.643434811522653, w0=73.63227245117312, w1=14.475704874754637\n",
      "GD iter. 19/49: loss=13.643434811522654, w0=73.63227245716372, w1=14.475704875932355\n",
      "GD iter. 20/49: loss=13.643434811522656, w0=73.6322724589609, w1=14.47570487628567\n",
      "GD iter. 21/49: loss=13.643434811522656, w0=73.63227245950004, w1=14.475704876391665\n",
      "GD iter. 22/49: loss=13.643434811522654, w0=73.63227245966179, w1=14.475704876423464\n",
      "GD iter. 23/49: loss=13.643434811522653, w0=73.63227245971032, w1=14.475704876433003\n",
      "GD iter. 24/49: loss=13.643434811522654, w0=73.63227245972487, w1=14.475704876435866\n",
      "GD iter. 25/49: loss=13.643434811522656, w0=73.63227245972924, w1=14.475704876436724\n",
      "GD iter. 26/49: loss=13.64343481152266, w0=73.63227245973054, w1=14.475704876436982\n",
      "GD iter. 27/49: loss=13.643434811522656, w0=73.63227245973094, w1=14.475704876437058\n",
      "GD iter. 28/49: loss=13.643434811522654, w0=73.63227245973106, w1=14.475704876437081\n",
      "GD iter. 29/49: loss=13.643434811522653, w0=73.6322724597311, w1=14.475704876437089\n",
      "GD iter. 30/49: loss=13.64343481152266, w0=73.63227245973111, w1=14.47570487643709\n",
      "GD iter. 31/49: loss=13.64343481152266, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 32/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 33/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 34/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 35/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 36/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 37/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 38/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 39/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 40/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 41/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 42/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 43/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 44/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 45/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 46/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 47/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 48/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 49/49: loss=13.643434811522662, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0., 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points \n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64764f8061af4213a57fe544e672c06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses, gd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(y, tx, w):\n",
    "\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss by MSE\n",
    "    # ***************************************************\n",
    "    e = y - tx @ w\n",
    "    return np.mean(np.abs(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "    # ***************************************************\n",
    "    e = y - tx @ w\n",
    "    abs_subgrad =  np.where(e >= 0, 1, -1) * np.where(e == 0, 0, 1)\n",
    "    return -abs_subgrad.dot(tx) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.285319214221363"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mae(y, tx, np.array([70, 15.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0318   ,  0.8211088])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_subgradient_mae(y, tx, np.array([70, 100.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD \n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute subgradient and loss\n",
    "        # ***************************************************\n",
    "        loss = compute_mae(y, tx, w)\n",
    "        grad_w = compute_subgradient_mae(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by subgradient\n",
    "        # ***************************************************\n",
    "        w -= gamma * grad_w\n",
    "        \n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=73.29392200210518, w0=0.2, w1=-2.1600499167107046e-16\n",
      "SubGD iter. 1/499: loss=73.09392200210517, w0=0.4, w1=-4.320099833421409e-16\n",
      "SubGD iter. 2/499: loss=72.89392200210517, w0=0.6000000000000001, w1=-6.480149750132114e-16\n",
      "SubGD iter. 3/499: loss=72.69392200210518, w0=0.8, w1=-8.640199666842818e-16\n",
      "SubGD iter. 4/499: loss=72.49392200210517, w0=1.0, w1=-1.0800249583553523e-15\n",
      "SubGD iter. 5/499: loss=72.29392200210518, w0=1.2, w1=-1.2960299500264228e-15\n",
      "SubGD iter. 6/499: loss=72.09392200210517, w0=1.4, w1=-1.5120349416974933e-15\n",
      "SubGD iter. 7/499: loss=71.89392200210517, w0=1.5999999999999999, w1=-1.7280399333685638e-15\n",
      "SubGD iter. 8/499: loss=71.69392200210518, w0=1.7999999999999998, w1=-1.944044925039634e-15\n",
      "SubGD iter. 9/499: loss=71.49392200210517, w0=1.9999999999999998, w1=-2.1600499167107045e-15\n",
      "SubGD iter. 10/499: loss=71.29392200210518, w0=2.1999999999999997, w1=-2.376054908381775e-15\n",
      "SubGD iter. 11/499: loss=71.09392200210517, w0=2.4, w1=-2.592059900052845e-15\n",
      "SubGD iter. 12/499: loss=70.89392200210517, w0=2.6, w1=-2.8080648917239155e-15\n",
      "SubGD iter. 13/499: loss=70.69392200210518, w0=2.8000000000000003, w1=-3.024069883394986e-15\n",
      "SubGD iter. 14/499: loss=70.49392200210517, w0=3.0000000000000004, w1=-3.240074875066056e-15\n",
      "SubGD iter. 15/499: loss=70.29392200210518, w0=3.2000000000000006, w1=-3.4560798667371265e-15\n",
      "SubGD iter. 16/499: loss=70.09392200210517, w0=3.400000000000001, w1=-3.672084858408197e-15\n",
      "SubGD iter. 17/499: loss=69.89392200210517, w0=3.600000000000001, w1=-3.8880898500792676e-15\n",
      "SubGD iter. 18/499: loss=69.69392200210518, w0=3.800000000000001, w1=-4.104094841750338e-15\n",
      "SubGD iter. 19/499: loss=69.49392200210517, w0=4.000000000000001, w1=-4.320099833421408e-15\n",
      "SubGD iter. 20/499: loss=69.29392200210518, w0=4.200000000000001, w1=-4.5361048250924786e-15\n",
      "SubGD iter. 21/499: loss=69.09392200210517, w0=4.400000000000001, w1=-4.752109816763549e-15\n",
      "SubGD iter. 22/499: loss=68.89392200210517, w0=4.600000000000001, w1=-4.968114808434619e-15\n",
      "SubGD iter. 23/499: loss=68.69392200210518, w0=4.800000000000002, w1=-5.1841198001056896e-15\n",
      "SubGD iter. 24/499: loss=68.49392200210517, w0=5.000000000000002, w1=-5.40012479177676e-15\n",
      "SubGD iter. 25/499: loss=68.29392200210518, w0=5.200000000000002, w1=-5.61612978344783e-15\n",
      "SubGD iter. 26/499: loss=68.09392200210517, w0=5.400000000000002, w1=-5.8321347751189006e-15\n",
      "SubGD iter. 27/499: loss=67.89392200210517, w0=5.600000000000002, w1=-6.048139766789971e-15\n",
      "SubGD iter. 28/499: loss=67.69392200210518, w0=5.8000000000000025, w1=-6.264144758461041e-15\n",
      "SubGD iter. 29/499: loss=67.49392200210517, w0=6.000000000000003, w1=-6.4801497501321116e-15\n",
      "SubGD iter. 30/499: loss=67.29392200210518, w0=6.200000000000003, w1=-6.696154741803182e-15\n",
      "SubGD iter. 31/499: loss=67.09392200210517, w0=6.400000000000003, w1=-6.912159733474252e-15\n",
      "SubGD iter. 32/499: loss=66.89392200210517, w0=6.600000000000003, w1=-7.128164725145323e-15\n",
      "SubGD iter. 33/499: loss=66.69392200210518, w0=6.800000000000003, w1=-7.344169716816393e-15\n",
      "SubGD iter. 34/499: loss=66.49392200210517, w0=7.0000000000000036, w1=-7.560174708487463e-15\n",
      "SubGD iter. 35/499: loss=66.29392200210518, w0=7.200000000000004, w1=-7.776179700158534e-15\n",
      "SubGD iter. 36/499: loss=66.09392200210517, w0=7.400000000000004, w1=-7.992184691829604e-15\n",
      "SubGD iter. 37/499: loss=65.89392200210517, w0=7.600000000000004, w1=-8.208189683500674e-15\n",
      "SubGD iter. 38/499: loss=65.69392200210515, w0=7.800000000000004, w1=-8.424194675171745e-15\n",
      "SubGD iter. 39/499: loss=65.49392200210517, w0=8.000000000000004, w1=-8.640199666842815e-15\n",
      "SubGD iter. 40/499: loss=65.29392200210518, w0=8.200000000000003, w1=-8.856204658513885e-15\n",
      "SubGD iter. 41/499: loss=65.09392200210517, w0=8.400000000000002, w1=-9.072209650184956e-15\n",
      "SubGD iter. 42/499: loss=64.89392200210517, w0=8.600000000000001, w1=-9.288214641856026e-15\n",
      "SubGD iter. 43/499: loss=64.69392200210518, w0=8.8, w1=-9.504219633527096e-15\n",
      "SubGD iter. 44/499: loss=64.49392200210517, w0=9.0, w1=-9.720224625198167e-15\n",
      "SubGD iter. 45/499: loss=64.29392200210518, w0=9.2, w1=-9.936229616869237e-15\n",
      "SubGD iter. 46/499: loss=64.09392200210517, w0=9.399999999999999, w1=-1.0152234608540307e-14\n",
      "SubGD iter. 47/499: loss=63.89392200210517, w0=9.599999999999998, w1=-1.0368239600211378e-14\n",
      "SubGD iter. 48/499: loss=63.69392200210518, w0=9.799999999999997, w1=-1.0584244591882448e-14\n",
      "SubGD iter. 49/499: loss=63.49392200210517, w0=9.999999999999996, w1=-1.0800249583553518e-14\n",
      "SubGD iter. 50/499: loss=63.29392200210517, w0=10.199999999999996, w1=-1.1016254575224589e-14\n",
      "SubGD iter. 51/499: loss=63.09392200210518, w0=10.399999999999995, w1=-1.1232259566895659e-14\n",
      "SubGD iter. 52/499: loss=62.89392200210517, w0=10.599999999999994, w1=-1.144826455856673e-14\n",
      "SubGD iter. 53/499: loss=62.69392200210518, w0=10.799999999999994, w1=-1.16642695502378e-14\n",
      "SubGD iter. 54/499: loss=62.49392200210517, w0=10.999999999999993, w1=-1.188027454190887e-14\n",
      "SubGD iter. 55/499: loss=62.29392200210517, w0=11.199999999999992, w1=-1.209627953357994e-14\n",
      "SubGD iter. 56/499: loss=62.09392200210518, w0=11.399999999999991, w1=-1.231228452525101e-14\n",
      "SubGD iter. 57/499: loss=61.893922002105185, w0=11.59999999999999, w1=-1.2528289516922081e-14\n",
      "SubGD iter. 58/499: loss=61.69392200210518, w0=11.79999999999999, w1=-1.2744294508593151e-14\n",
      "SubGD iter. 59/499: loss=61.49392200210518, w0=11.99999999999999, w1=-1.2960299500264222e-14\n",
      "SubGD iter. 60/499: loss=61.293922002105184, w0=12.199999999999989, w1=-1.3176304491935292e-14\n",
      "SubGD iter. 61/499: loss=61.09392200210518, w0=12.399999999999988, w1=-1.3392309483606362e-14\n",
      "SubGD iter. 62/499: loss=60.893922002105185, w0=12.599999999999987, w1=-1.3608314475277433e-14\n",
      "SubGD iter. 63/499: loss=60.69392200210518, w0=12.799999999999986, w1=-1.3824319466948503e-14\n",
      "SubGD iter. 64/499: loss=60.49392200210518, w0=12.999999999999986, w1=-1.4040324458619573e-14\n",
      "SubGD iter. 65/499: loss=60.293922002105184, w0=13.199999999999985, w1=-1.4256329450290645e-14\n",
      "SubGD iter. 66/499: loss=60.09392200210518, w0=13.399999999999984, w1=-1.4472334441961717e-14\n",
      "SubGD iter. 67/499: loss=59.89392200210519, w0=13.599999999999984, w1=-1.468833943363279e-14\n",
      "SubGD iter. 68/499: loss=59.69392200210518, w0=13.799999999999983, w1=-1.490434442530386e-14\n",
      "SubGD iter. 69/499: loss=59.493922002105194, w0=13.999999999999982, w1=-1.5120349416974933e-14\n",
      "SubGD iter. 70/499: loss=59.29392200210519, w0=14.199999999999982, w1=-1.5336354408646005e-14\n",
      "SubGD iter. 71/499: loss=59.093922002105195, w0=14.39999999999998, w1=-1.5552359400317077e-14\n",
      "SubGD iter. 72/499: loss=58.89392200210519, w0=14.59999999999998, w1=-1.576836439198815e-14\n",
      "SubGD iter. 73/499: loss=58.6939220021052, w0=14.79999999999998, w1=-1.598436938365922e-14\n",
      "SubGD iter. 74/499: loss=58.493922002105194, w0=14.999999999999979, w1=-1.6200374375330292e-14\n",
      "SubGD iter. 75/499: loss=58.29392200210519, w0=15.199999999999978, w1=-1.6416379367001364e-14\n",
      "SubGD iter. 76/499: loss=58.093922002105195, w0=15.399999999999977, w1=-1.6632384358672436e-14\n",
      "SubGD iter. 77/499: loss=57.89392200210519, w0=15.599999999999977, w1=-1.6848389350343508e-14\n",
      "SubGD iter. 78/499: loss=57.6939220021052, w0=15.799999999999976, w1=-1.706439434201458e-14\n",
      "SubGD iter. 79/499: loss=57.493922002105194, w0=15.999999999999975, w1=-1.7280399333685652e-14\n",
      "SubGD iter. 80/499: loss=57.29392200210519, w0=16.199999999999974, w1=-1.7496404325356724e-14\n",
      "SubGD iter. 81/499: loss=57.093922002105195, w0=16.399999999999974, w1=-1.7712409317027796e-14\n",
      "SubGD iter. 82/499: loss=56.89392200210521, w0=16.599999999999973, w1=-1.7928414308698868e-14\n",
      "SubGD iter. 83/499: loss=56.693922002105204, w0=16.799999999999972, w1=-1.814441930036994e-14\n",
      "SubGD iter. 84/499: loss=56.49392200210521, w0=16.99999999999997, w1=-1.836042429204101e-14\n",
      "SubGD iter. 85/499: loss=56.293922002105205, w0=17.19999999999997, w1=-1.8576429283712083e-14\n",
      "SubGD iter. 86/499: loss=56.0939220021052, w0=17.39999999999997, w1=-1.8792434275383155e-14\n",
      "SubGD iter. 87/499: loss=55.89392200210521, w0=17.59999999999997, w1=-1.9008439267054227e-14\n",
      "SubGD iter. 88/499: loss=55.693922002105204, w0=17.79999999999997, w1=-1.92244442587253e-14\n",
      "SubGD iter. 89/499: loss=55.49392200210521, w0=17.999999999999968, w1=-1.944044925039637e-14\n",
      "SubGD iter. 90/499: loss=55.293922002105205, w0=18.199999999999967, w1=-1.9656454242067443e-14\n",
      "SubGD iter. 91/499: loss=55.0939220021052, w0=18.399999999999967, w1=-1.9872459233738515e-14\n",
      "SubGD iter. 92/499: loss=54.89392200210521, w0=18.599999999999966, w1=-2.0088464225409587e-14\n",
      "SubGD iter. 93/499: loss=54.693922002105204, w0=18.799999999999965, w1=-2.030446921708066e-14\n",
      "SubGD iter. 94/499: loss=54.49392200210521, w0=18.999999999999964, w1=-2.052047420875173e-14\n",
      "SubGD iter. 95/499: loss=54.29392200210522, w0=19.199999999999964, w1=-2.0736479200422802e-14\n",
      "SubGD iter. 96/499: loss=54.0939220021052, w0=19.399999999999963, w1=-2.0952484192093874e-14\n",
      "SubGD iter. 97/499: loss=53.89392200210521, w0=19.599999999999962, w1=-2.1168489183764946e-14\n",
      "SubGD iter. 98/499: loss=53.693922002105204, w0=19.79999999999996, w1=-2.1384494175436018e-14\n",
      "SubGD iter. 99/499: loss=53.493922002105215, w0=19.99999999999996, w1=-2.160049916710709e-14\n",
      "SubGD iter. 100/499: loss=53.29392200210522, w0=20.19999999999996, w1=-2.1816504158778162e-14\n",
      "SubGD iter. 101/499: loss=53.0939220021052, w0=20.39999999999996, w1=-2.2032509150449234e-14\n",
      "SubGD iter. 102/499: loss=52.893922002105214, w0=20.59999999999996, w1=-2.2248514142120306e-14\n",
      "SubGD iter. 103/499: loss=52.69392200210522, w0=20.799999999999958, w1=-2.2464519133791378e-14\n",
      "SubGD iter. 104/499: loss=52.493922002105215, w0=20.999999999999957, w1=-2.268052412546245e-14\n",
      "SubGD iter. 105/499: loss=52.29392200210522, w0=21.199999999999957, w1=-2.289652911713352e-14\n",
      "SubGD iter. 106/499: loss=52.093922002105224, w0=21.399999999999956, w1=-2.3112534108804593e-14\n",
      "SubGD iter. 107/499: loss=51.893922002105214, w0=21.599999999999955, w1=-2.3328539100475665e-14\n",
      "SubGD iter. 108/499: loss=51.69392200210522, w0=21.799999999999955, w1=-2.3544544092146737e-14\n",
      "SubGD iter. 109/499: loss=51.493922002105215, w0=21.999999999999954, w1=-2.376054908381781e-14\n",
      "SubGD iter. 110/499: loss=51.29392200210523, w0=22.199999999999953, w1=-2.397655407548888e-14\n",
      "SubGD iter. 111/499: loss=51.093922002105224, w0=22.399999999999952, w1=-2.4192559067159953e-14\n",
      "SubGD iter. 112/499: loss=50.89392200210522, w0=22.59999999999995, w1=-2.4408564058831025e-14\n",
      "SubGD iter. 113/499: loss=50.69392200210522, w0=22.79999999999995, w1=-2.4624569050502097e-14\n",
      "SubGD iter. 114/499: loss=50.49392200210523, w0=22.99999999999995, w1=-2.484057404217317e-14\n",
      "SubGD iter. 115/499: loss=50.29392200210523, w0=23.19999999999995, w1=-2.505657903384424e-14\n",
      "SubGD iter. 116/499: loss=50.093922002105224, w0=23.39999999999995, w1=-2.5272584025515313e-14\n",
      "SubGD iter. 117/499: loss=49.89392200210523, w0=23.599999999999948, w1=-2.5488589017186384e-14\n",
      "SubGD iter. 118/499: loss=49.69392200210523, w0=23.799999999999947, w1=-2.5704594008857456e-14\n",
      "SubGD iter. 119/499: loss=49.49392200210523, w0=23.999999999999947, w1=-2.5920599000528528e-14\n",
      "SubGD iter. 120/499: loss=49.29392200210523, w0=24.199999999999946, w1=-2.61366039921996e-14\n",
      "SubGD iter. 121/499: loss=49.093922002105224, w0=24.399999999999945, w1=-2.6352608983870672e-14\n",
      "SubGD iter. 122/499: loss=48.893922002105235, w0=24.599999999999945, w1=-2.6568613975541744e-14\n",
      "SubGD iter. 123/499: loss=48.69392200210523, w0=24.799999999999944, w1=-2.6784618967212816e-14\n",
      "SubGD iter. 124/499: loss=48.49392200210523, w0=24.999999999999943, w1=-2.7000623958883888e-14\n",
      "SubGD iter. 125/499: loss=48.29392200210523, w0=25.199999999999942, w1=-2.721662895055496e-14\n",
      "SubGD iter. 126/499: loss=48.09392200210524, w0=25.39999999999994, w1=-2.7432633942226032e-14\n",
      "SubGD iter. 127/499: loss=47.893922002105235, w0=25.59999999999994, w1=-2.7648638933897104e-14\n",
      "SubGD iter. 128/499: loss=47.69392200210523, w0=25.79999999999994, w1=-2.7864643925568175e-14\n",
      "SubGD iter. 129/499: loss=47.49392200210523, w0=25.99999999999994, w1=-2.8080648917239247e-14\n",
      "SubGD iter. 130/499: loss=47.29392200210524, w0=26.19999999999994, w1=-2.829665390891032e-14\n",
      "SubGD iter. 131/499: loss=47.09392200210524, w0=26.399999999999938, w1=-2.851265890058139e-14\n",
      "SubGD iter. 132/499: loss=46.893922002105235, w0=26.599999999999937, w1=-2.872866389225246e-14\n",
      "SubGD iter. 133/499: loss=46.69392200210523, w0=26.799999999999937, w1=-2.8944668883923535e-14\n",
      "SubGD iter. 134/499: loss=46.493922002105236, w0=26.999999999999936, w1=-2.916067387559461e-14\n",
      "SubGD iter. 135/499: loss=46.29392200210524, w0=27.199999999999935, w1=-2.937667886726568e-14\n",
      "SubGD iter. 136/499: loss=46.09392200210524, w0=27.399999999999935, w1=-2.959268385893675e-14\n",
      "SubGD iter. 137/499: loss=45.893922002105235, w0=27.599999999999934, w1=-2.980868885060782e-14\n",
      "SubGD iter. 138/499: loss=45.69392200210524, w0=27.799999999999933, w1=-3.0024693842278895e-14\n",
      "SubGD iter. 139/499: loss=45.49392200210524, w0=27.999999999999932, w1=-3.0240698833949967e-14\n",
      "SubGD iter. 140/499: loss=45.29392200210524, w0=28.199999999999932, w1=-3.045670382562104e-14\n",
      "SubGD iter. 141/499: loss=45.09392200210524, w0=28.39999999999993, w1=-3.067270881729211e-14\n",
      "SubGD iter. 142/499: loss=44.89392200210524, w0=28.59999999999993, w1=-3.088871380896318e-14\n",
      "SubGD iter. 143/499: loss=44.693922002105246, w0=28.79999999999993, w1=-3.1104718800634254e-14\n",
      "SubGD iter. 144/499: loss=44.49392200210524, w0=28.99999999999993, w1=-3.1320723792305326e-14\n",
      "SubGD iter. 145/499: loss=44.29392200210525, w0=29.19999999999993, w1=-3.15367287839764e-14\n",
      "SubGD iter. 146/499: loss=44.09392200210524, w0=29.399999999999928, w1=-3.175273377564747e-14\n",
      "SubGD iter. 147/499: loss=43.89392723059973, w0=29.59995999999993, w1=0.00012584736291345054\n",
      "SubGD iter. 148/499: loss=43.69400714341194, w0=29.79991999999993, w1=0.0002516947258586538\n",
      "SubGD iter. 149/499: loss=43.494087056224146, w0=29.99987999999993, w1=0.0003775420888038571\n",
      "SubGD iter. 150/499: loss=43.29416696903634, w0=30.19983999999993, w1=0.0005033894517490604\n",
      "SubGD iter. 151/499: loss=43.09424688184855, w0=30.39979999999993, w1=0.0006292368146942637\n",
      "SubGD iter. 152/499: loss=42.894326794660756, w0=30.599759999999932, w1=0.000755084177639467\n",
      "SubGD iter. 153/499: loss=42.694406707472965, w0=30.799719999999933, w1=0.0008809315405846703\n",
      "SubGD iter. 154/499: loss=42.49448662028517, w0=30.999679999999934, w1=0.0010067789035298736\n",
      "SubGD iter. 155/499: loss=42.294566533097374, w0=31.199639999999935, w1=0.0011326262664750769\n",
      "SubGD iter. 156/499: loss=42.094646445909575, w0=31.399599999999936, w1=0.0012584736294202802\n",
      "SubGD iter. 157/499: loss=41.8947419650319, w0=31.599519999999934, w1=0.001495560128833877\n",
      "SubGD iter. 158/499: loss=41.694901651981866, w0=31.799439999999933, w1=0.001732646628247474\n",
      "SubGD iter. 159/499: loss=41.49506133893182, w0=31.999359999999932, w1=0.001969733127661071\n",
      "SubGD iter. 160/499: loss=41.29522102588178, w0=32.19927999999993, w1=0.002206819627074668\n",
      "SubGD iter. 161/499: loss=41.095380712831734, w0=32.39919999999993, w1=0.0024439061264882648\n",
      "SubGD iter. 162/499: loss=40.895540399781694, w0=32.59911999999993, w1=0.0026809926259018617\n",
      "SubGD iter. 163/499: loss=40.695735720665056, w0=32.79899999999993, w1=0.0030402488835083712\n",
      "SubGD iter. 164/499: loss=40.495975003339765, w0=32.99887999999993, w1=0.0033995051411148808\n",
      "SubGD iter. 165/499: loss=40.29621428601447, w0=33.19875999999993, w1=0.0037587613987213903\n",
      "SubGD iter. 166/499: loss=40.09648584616454, w0=33.39859999999993, w1=0.00421173931312714\n",
      "SubGD iter. 167/499: loss=39.8968046922196, w0=33.59843999999993, w1=0.004664717227532889\n",
      "SubGD iter. 168/499: loss=39.69712353827464, w0=33.798279999999934, w1=0.005117695141938638\n",
      "SubGD iter. 169/499: loss=39.49744238432968, w0=33.998119999999936, w1=0.005570673056344387\n",
      "SubGD iter. 170/499: loss=39.29776123038472, w0=34.19795999999994, w1=0.006023650970750137\n",
      "SubGD iter. 171/499: loss=39.098080076439764, w0=34.39779999999994, w1=0.006476628885155886\n",
      "SubGD iter. 172/499: loss=38.89839892249481, w0=34.59763999999994, w1=0.006929606799561635\n",
      "SubGD iter. 173/499: loss=38.698717768549855, w0=34.79747999999994, w1=0.0073825847139673845\n",
      "SubGD iter. 174/499: loss=38.4990366146049, w0=34.997319999999945, w1=0.007835562628373134\n",
      "SubGD iter. 175/499: loss=38.29935546065994, w0=35.19715999999995, w1=0.008288540542778883\n",
      "SubGD iter. 176/499: loss=38.09967430671498, w0=35.39699999999995, w1=0.008741518457184632\n",
      "SubGD iter. 177/499: loss=37.90003126351928, w0=35.596759999999946, w1=0.009385341898287155\n",
      "SubGD iter. 178/499: loss=37.70050890297616, w0=35.796519999999944, w1=0.010029165339389677\n",
      "SubGD iter. 179/499: loss=37.50100236838585, w0=35.99623999999994, w1=0.010792487914452554\n",
      "SubGD iter. 180/499: loss=37.301563890057444, w0=36.195919999999944, w1=0.011655652083369617\n",
      "SubGD iter. 181/499: loss=37.10219965279553, w0=36.395599999999945, w1=0.012518816252286681\n",
      "SubGD iter. 182/499: loss=36.902835415533616, w0=36.595279999999946, w1=0.013381980421203745\n",
      "SubGD iter. 183/499: loss=36.703471178271705, w0=36.794959999999946, w1=0.01424514459012081\n",
      "SubGD iter. 184/499: loss=36.504146097917214, w0=36.99459999999995, w1=0.015214966023733161\n",
      "SubGD iter. 185/499: loss=36.30486074714916, w0=37.19423999999995, w1=0.01618478745734551\n",
      "SubGD iter. 186/499: loss=36.10557539638108, w0=37.39387999999995, w1=0.01715460889095786\n",
      "SubGD iter. 187/499: loss=35.90629982069491, w0=37.59347999999995, w1=0.01818713325243656\n",
      "SubGD iter. 188/499: loss=35.70709369016213, w0=37.79307999999995, w1=0.019219657613915257\n",
      "SubGD iter. 189/499: loss=35.507898812871474, w0=37.992639999999945, w1=0.02034093576500603\n",
      "SubGD iter. 190/499: loss=35.30877155854801, w0=38.19219999999994, w1=0.021462213916096807\n",
      "SubGD iter. 191/499: loss=35.10964548208684, w0=38.39171999999994, w1=0.022683115557667347\n",
      "SubGD iter. 192/499: loss=34.91062373058721, w0=38.591159999999945, w1=0.02410083231748391\n",
      "SubGD iter. 193/499: loss=34.71173211298315, w0=38.79059999999995, w1=0.025518549077300473\n",
      "SubGD iter. 194/499: loss=34.51287920031405, w0=38.989999999999945, w1=0.027038358146586727\n",
      "SubGD iter. 195/499: loss=34.31410181882524, w0=39.189319999999945, w1=0.028777581703816096\n",
      "SubGD iter. 196/499: loss=34.11549496945963, w0=39.38855999999995, w1=0.030662525584177792\n",
      "SubGD iter. 197/499: loss=33.91703223407291, w0=39.587759999999946, w1=0.032636536721432394\n",
      "SubGD iter. 198/499: loss=33.71862937783667, w0=39.78687999999995, w1=0.03475017191419314\n",
      "SubGD iter. 199/499: loss=33.52037526907799, w0=39.98595999999995, w1=0.03697050109842847\n",
      "SubGD iter. 200/499: loss=33.3222218130053, w0=40.184999999999945, w1=0.0392832180363377\n",
      "SubGD iter. 201/499: loss=33.12411046170714, w0=40.38403999999994, w1=0.04159593497424693\n",
      "SubGD iter. 202/499: loss=32.92602837996749, w0=40.58303999999994, w1=0.04402333976985938\n",
      "SubGD iter. 203/499: loss=32.72804455552032, w0=40.78195999999994, w1=0.046667299188465024\n",
      "SubGD iter. 204/499: loss=32.53024680961832, w0=40.98071999999994, w1=0.049688506618546124\n",
      "SubGD iter. 205/499: loss=32.332730945541954, w0=41.179399999999944, w1=0.052906251876889035\n",
      "SubGD iter. 206/499: loss=32.13535408689529, w0=41.377959999999945, w1=0.05636299464000064\n",
      "SubGD iter. 207/499: loss=31.938225526587438, w0=41.57639999999994, w1=0.060051942404832866\n",
      "SubGD iter. 208/499: loss=31.74135436122599, w0=41.774719999999945, w1=0.06402941699679093\n",
      "SubGD iter. 209/499: loss=31.544667623926873, w0=41.97287999999995, w1=0.06837033376295794\n",
      "SubGD iter. 210/499: loss=31.348308195212454, w0=42.17083999999995, w1=0.07309521945988005\n",
      "SubGD iter. 211/499: loss=31.15235309293394, w0=42.36863999999995, w1=0.07815851383694077\n",
      "SubGD iter. 212/499: loss=30.956615105874462, w0=42.56639999999995, w1=0.08330846960409183\n",
      "SubGD iter. 213/499: loss=30.76102492209563, w0=42.76399999999995, w1=0.08871906440018015\n",
      "SubGD iter. 214/499: loss=30.565699517699656, w0=42.96147999999995, w1=0.09440401958763148\n",
      "SubGD iter. 215/499: loss=30.370610133102385, w0=43.158839999999955, w1=0.10034426301409108\n",
      "SubGD iter. 216/499: loss=30.175734964343178, w0=43.35603999999996, w1=0.1066319568259988\n",
      "SubGD iter. 217/499: loss=29.98117267461881, w0=43.55307999999996, w1=0.11326246609913937\n",
      "SubGD iter. 218/499: loss=29.786874120489834, w0=43.74999999999996, w1=0.12013965362732959\n",
      "SubGD iter. 219/499: loss=29.59289154970509, w0=43.946599999999954, w1=0.12761271355972234\n",
      "SubGD iter. 220/499: loss=29.399414293141362, w0=44.14311999999995, w1=0.13524169717037787\n",
      "SubGD iter. 221/499: loss=29.206234269343845, w0=44.33927999999995, w1=0.14359931288866548\n",
      "SubGD iter. 222/499: loss=29.013636971965642, w0=44.535159999999955, w1=0.15245478172547056\n",
      "SubGD iter. 223/499: loss=28.82148328828996, w0=44.730919999999955, w1=0.1615249570296148\n",
      "SubGD iter. 224/499: loss=28.629583462849386, w0=44.92639999999996, w1=0.17114506968371448\n",
      "SubGD iter. 225/499: loss=28.43811792896095, w0=45.12175999999996, w1=0.18098301094957464\n",
      "SubGD iter. 226/499: loss=28.24695808689776, w0=45.31671999999996, w1=0.19158007613250613\n",
      "SubGD iter. 227/499: loss=28.05646404726138, w0=45.51143999999996, w1=0.20266115674049784\n",
      "SubGD iter. 228/499: loss=27.866388693416987, w0=45.70587999999996, w1=0.2142770203307216\n",
      "SubGD iter. 229/499: loss=27.67674983634022, w0=45.90007999999996, w1=0.2263797736924627\n",
      "SubGD iter. 230/499: loss=27.487547118332692, w0=46.09407999999996, w1=0.23877703079281887\n",
      "SubGD iter. 231/499: loss=27.29875950740035, w0=46.287719999999965, w1=0.2517502797471572\n",
      "SubGD iter. 232/499: loss=27.11057427514043, w0=46.48095999999997, w1=0.2654198629571689\n",
      "SubGD iter. 233/499: loss=26.92307140287747, w0=46.673959999999965, w1=0.2794774489186981\n",
      "SubGD iter. 234/499: loss=26.73596341098813, w0=46.86667999999997, w1=0.29400962513052004\n",
      "SubGD iter. 235/499: loss=26.54929898198173, w0=47.05903999999997, w1=0.3091185280276233\n",
      "SubGD iter. 236/499: loss=26.36343428089692, w0=47.250719999999966, w1=0.3253355789490659\n",
      "SubGD iter. 237/499: loss=26.17863275722956, w0=47.44187999999997, w1=0.34241897590554166\n",
      "SubGD iter. 238/499: loss=25.994625285406855, w0=47.63267999999997, w1=0.3600700758730524\n",
      "SubGD iter. 239/499: loss=25.811227178642884, w0=47.82295999999997, w1=0.3785258871502862\n",
      "SubGD iter. 240/499: loss=25.628566051796117, w0=48.013039999999975, w1=0.3973530754571569\n",
      "SubGD iter. 241/499: loss=25.44637325811235, w0=48.202639999999974, w1=0.4169680330952347\n",
      "SubGD iter. 242/499: loss=25.264831010395014, w0=48.39187999999997, w1=0.43713520834695324\n",
      "SubGD iter. 243/499: loss=25.083824383660826, w0=48.58091999999997, w1=0.4576980992746599\n",
      "SubGD iter. 244/499: loss=24.903167713802063, w0=48.76959999999997, w1=0.47888536111071106\n",
      "SubGD iter. 245/499: loss=24.722987599289635, w0=48.95799999999997, w1=0.5005478073702241\n",
      "SubGD iter. 246/499: loss=24.54333609044661, w0=49.14599999999997, w1=0.52277857189894\n",
      "SubGD iter. 247/499: loss=24.364308551177267, w0=49.33347999999997, w1=0.5459110542352247\n",
      "SubGD iter. 248/499: loss=24.18602798320031, w0=49.52063999999997, w1=0.569592061783981\n",
      "SubGD iter. 249/499: loss=24.008308832735533, w0=49.70727999999997, w1=0.594045576540927\n",
      "SubGD iter. 250/499: loss=23.831366044304794, w0=49.89343999999997, w1=0.6192247911542609\n",
      "SubGD iter. 251/499: loss=23.655097614325708, w0=50.07899999999997, w1=0.6452831401476534\n",
      "SubGD iter. 252/499: loss=23.47972369976787, w0=50.264159999999976, w1=0.6719700504478103\n",
      "SubGD iter. 253/499: loss=23.30499224509445, w0=50.448639999999976, w1=0.6996327717941271\n",
      "SubGD iter. 254/499: loss=23.131131781739068, w0=50.63271999999998, w1=0.7279602829300182\n",
      "SubGD iter. 255/499: loss=22.957837726616187, w0=50.81639999999998, w1=0.7569252661490921\n",
      "SubGD iter. 256/499: loss=22.785126599952765, w0=50.99943999999998, w1=0.7867579289728804\n",
      "SubGD iter. 257/499: loss=22.613273388728274, w0=51.182119999999976, w1=0.8171669782586202\n",
      "SubGD iter. 258/499: loss=22.441992132782495, w0=51.36415999999998, w1=0.8485103244283394\n",
      "SubGD iter. 259/499: loss=22.271557059724802, w0=51.54559999999998, w1=0.8806916151200291\n",
      "SubGD iter. 260/499: loss=22.10204066954862, w0=51.72635999999998, w1=0.9138474597828462\n",
      "SubGD iter. 261/499: loss=21.93332102606073, w0=51.90667999999998, w1=0.9475881159764308\n",
      "SubGD iter. 262/499: loss=21.765212846204093, w0=52.08643999999998, w1=0.9821312612673154\n",
      "SubGD iter. 263/499: loss=21.597945316961685, w0=52.265439999999984, w1=1.0177513983247668\n",
      "SubGD iter. 264/499: loss=21.431615250666496, w0=52.44383999999999, w1=1.0542469362146414\n",
      "SubGD iter. 265/499: loss=21.266019325514485, w0=52.62159999999999, w1=1.0915926783845273\n",
      "SubGD iter. 266/499: loss=21.101171337357535, w0=52.798799999999986, w1=1.129619085556673\n",
      "SubGD iter. 267/499: loss=20.93711961517092, w0=52.97551999999999, w1=1.1683084807033406\n",
      "SubGD iter. 268/499: loss=20.773689127932435, w0=53.15159999999999, w1=1.2078965511363908\n",
      "SubGD iter. 269/499: loss=20.6109943395999, w0=53.327159999999985, w1=1.2482689471384465\n",
      "SubGD iter. 270/499: loss=20.448858176010468, w0=53.502279999999985, w1=1.2892595598148995\n",
      "SubGD iter. 271/499: loss=20.287366714340234, w0=53.67675999999999, w1=1.3311222032750978\n",
      "SubGD iter. 272/499: loss=20.12652512042239, w0=53.85071999999999, w1=1.3735902519374499\n",
      "SubGD iter. 273/499: loss=19.96631137853168, w0=54.02407999999999, w1=1.4168534473012706\n",
      "SubGD iter. 274/499: loss=19.806842228887685, w0=54.19679999999999, w1=1.4609199740207381\n",
      "SubGD iter. 275/499: loss=19.648117057226838, w0=54.36883999999999, w1=1.505893631538197\n",
      "SubGD iter. 276/499: loss=19.490111657640323, w0=54.540319999999994, w1=1.5516487514902246\n",
      "SubGD iter. 277/499: loss=19.3328538051315, w0=54.71115999999999, w1=1.5981748690845574\n",
      "SubGD iter. 278/499: loss=19.176289890984503, w0=54.881359999999994, w1=1.6455013719888805\n",
      "SubGD iter. 279/499: loss=19.02052588557835, w0=55.05067999999999, w1=1.693816993270765\n",
      "SubGD iter. 280/499: loss=18.865731853590013, w0=55.219159999999995, w1=1.7430968685119774\n",
      "SubGD iter. 281/499: loss=18.71178227942651, w0=55.38719999999999, w1=1.792963524133819\n",
      "SubGD iter. 282/499: loss=18.558356863196344, w0=55.554559999999995, w1=1.8436228829756138\n",
      "SubGD iter. 283/499: loss=18.405768077260603, w0=55.720839999999995, w1=1.8956104254681716\n",
      "SubGD iter. 284/499: loss=18.254207604075084, w0=55.88632, w1=1.9485727598164577\n",
      "SubGD iter. 285/499: loss=18.103367864208195, w0=56.05144, w1=2.0019509204788144\n",
      "SubGD iter. 286/499: loss=17.952930801293935, w0=56.21596, w1=2.056089907491043\n",
      "SubGD iter. 287/499: loss=17.803150107745484, w0=56.379760000000005, w1=2.110986513532909\n",
      "SubGD iter. 288/499: loss=17.65411737458352, w0=56.542840000000005, w1=2.166620956377608\n",
      "SubGD iter. 289/499: loss=17.50598597452782, w0=56.705040000000004, w1=2.2230384170670168\n",
      "SubGD iter. 290/499: loss=17.358703047799338, w0=56.86672, w1=2.279971782996793\n",
      "SubGD iter. 291/499: loss=17.212066401917713, w0=57.027480000000004, w1=2.3377119566759146\n",
      "SubGD iter. 292/499: loss=17.066393845837958, w0=57.18748, w1=2.3962640033424214\n",
      "SubGD iter. 293/499: loss=16.921363043306883, w0=57.34704, w1=2.4552338375796032\n",
      "SubGD iter. 294/499: loss=16.776899436168186, w0=57.50572, w1=2.515003368324168\n",
      "SubGD iter. 295/499: loss=16.63335363209859, w0=57.663639999999994, w1=2.5754573752615983\n",
      "SubGD iter. 296/499: loss=16.490613089330097, w0=57.82064, w1=2.636751149478865\n",
      "SubGD iter. 297/499: loss=16.34874594499509, w0=57.97692, w1=2.6987861938574924\n",
      "SubGD iter. 298/499: loss=16.207542789040353, w0=58.13268, w1=2.761377107309706\n",
      "SubGD iter. 299/499: loss=16.06676825881544, w0=58.28776, w1=2.8245975031776944\n",
      "SubGD iter. 300/499: loss=15.926673785113133, w0=58.442119999999996, w1=2.888559553587514\n",
      "SubGD iter. 301/499: loss=15.787194181178249, w0=58.596, w1=2.9529819258464483\n",
      "SubGD iter. 302/499: loss=15.648264637913867, w0=58.74892, w1=3.018330257622551\n",
      "SubGD iter. 303/499: loss=15.51011650703044, w0=58.90112, w1=3.084325154239983\n",
      "SubGD iter. 304/499: loss=15.372674992104312, w0=59.05256, w1=3.1509486558391426\n",
      "SubGD iter. 305/499: loss=15.235946427053918, w0=59.20328, w1=3.218296737662822\n",
      "SubGD iter. 306/499: loss=15.099812991434568, w0=59.35328, w1=3.286333233025128\n",
      "SubGD iter. 307/499: loss=14.964284447691641, w0=59.5028, w1=3.354724176314718\n",
      "SubGD iter. 308/499: loss=14.82929278030248, w0=59.6514, w1=3.424033621661605\n",
      "SubGD iter. 309/499: loss=14.695040177094846, w0=59.79916, w1=3.49397977501512\n",
      "SubGD iter. 310/499: loss=14.561639965924824, w0=59.94604, w1=3.56448228601535\n",
      "SubGD iter. 311/499: loss=14.429098722531336, w0=60.09196, w1=3.635785564441759\n",
      "SubGD iter. 312/499: loss=14.297410558465042, w0=60.23712, w1=3.7077270361894326\n",
      "SubGD iter. 313/499: loss=14.166336203332053, w0=60.3816, w1=3.7801516642705453\n",
      "SubGD iter. 314/499: loss=14.035976663401726, w0=60.52504, w1=3.8533821685533343\n",
      "SubGD iter. 315/499: loss=13.906448416805512, w0=60.667719999999996, w1=3.9272852327590777\n",
      "SubGD iter. 316/499: loss=13.7774668050404, w0=60.80992, w1=4.001569145481144\n",
      "SubGD iter. 317/499: loss=13.648895758581313, w0=60.95164, w1=4.076192297664982\n",
      "SubGD iter. 318/499: loss=13.52077867999521, w0=61.09276, w1=4.151209438802006\n",
      "SubGD iter. 319/499: loss=13.393214053421575, w0=61.23316, w1=4.226800030447909\n",
      "SubGD iter. 320/499: loss=13.266230135583273, w0=61.372879999999995, w1=4.302812142128262\n",
      "SubGD iter. 321/499: loss=13.139834633632168, w0=61.51208, w1=4.379181050473898\n",
      "SubGD iter. 322/499: loss=13.013947885500768, w0=61.65052, w1=4.455955926661648\n",
      "SubGD iter. 323/499: loss=12.888822569265669, w0=61.7882, w1=4.533263353747152\n",
      "SubGD iter. 324/499: loss=12.764351684514818, w0=61.92508, w1=4.611101258662853\n",
      "SubGD iter. 325/499: loss=12.640490324830989, w0=62.061440000000005, w1=4.689368634185708\n",
      "SubGD iter. 326/499: loss=12.517043832871211, w0=62.19704, w1=4.768115264376897\n",
      "SubGD iter. 327/499: loss=12.394340332717348, w0=62.33184, w1=4.8471860673101155\n",
      "SubGD iter. 328/499: loss=12.272365686109008, w0=62.4658, w1=4.926755628662254\n",
      "SubGD iter. 329/499: loss=12.151133219547233, w0=62.59912, w1=5.00669837442536\n",
      "SubGD iter. 330/499: loss=12.030432712688945, w0=62.7318, w1=5.087042417032119\n",
      "SubGD iter. 331/499: loss=11.910311744913308, w0=62.86364, w1=5.167848393003913\n",
      "SubGD iter. 332/499: loss=11.790958675984992, w0=62.994879999999995, w1=5.248767963149058\n",
      "SubGD iter. 333/499: loss=11.672323845450217, w0=63.125319999999995, w1=5.329966832560827\n",
      "SubGD iter. 334/499: loss=11.554502416691047, w0=63.254999999999995, w1=5.411445309199623\n",
      "SubGD iter. 335/499: loss=11.43743352467162, w0=63.383759999999995, w1=5.493457998530983\n",
      "SubGD iter. 336/499: loss=11.321075150069143, w0=63.51163999999999, w1=5.575929921535311\n",
      "SubGD iter. 337/499: loss=11.205420908987737, w0=63.63895999999999, w1=5.6586344279302025\n",
      "SubGD iter. 338/499: loss=11.09037150340541, w0=63.76563999999999, w1=5.741447908827745\n",
      "SubGD iter. 339/499: loss=10.975979963594332, w0=63.891679999999994, w1=5.824498436700759\n",
      "SubGD iter. 340/499: loss=10.862206355007798, w0=64.017, w1=5.907926675695662\n",
      "SubGD iter. 341/499: loss=10.749090823497262, w0=64.14152, w1=5.991519465072799\n",
      "SubGD iter. 342/499: loss=10.63679221230703, w0=64.26528, w1=6.075304535164891\n",
      "SubGD iter. 343/499: loss=10.525418945916602, w0=64.3878, w1=6.15953990459182\n",
      "SubGD iter. 344/499: loss=10.415041678111805, w0=64.50976, w1=6.243877652086345\n",
      "SubGD iter. 345/499: loss=10.305366680418013, w0=64.63072, w1=6.328598398250622\n",
      "SubGD iter. 346/499: loss=10.1965411386188, w0=64.75063999999999, w1=6.413637852953386\n",
      "SubGD iter. 347/499: loss=10.088693295462985, w0=64.86999999999999, w1=6.498601500706958\n",
      "SubGD iter. 348/499: loss=9.981579884636675, w0=64.98867999999999, w1=6.583391676326888\n",
      "SubGD iter. 349/499: loss=9.875463143957584, w0=65.10643999999999, w1=6.668314352733999\n",
      "SubGD iter. 350/499: loss=9.770327174415733, w0=65.22323999999999, w1=6.753348661368729\n",
      "SubGD iter. 351/499: loss=9.66616252892745, w0=65.33935999999999, w1=6.838405871333516\n",
      "SubGD iter. 352/499: loss=9.562751695814708, w0=65.45499999999998, w1=6.923432487482099\n",
      "SubGD iter. 353/499: loss=9.459898305425336, w0=65.56995999999998, w1=7.008481902929802\n",
      "SubGD iter. 354/499: loss=9.357884238399446, w0=65.68399999999998, w1=7.093712063080521\n",
      "SubGD iter. 355/499: loss=9.256825874027644, w0=65.79715999999998, w1=7.179015780289877\n",
      "SubGD iter. 356/499: loss=9.156611044553875, w0=65.90935999999998, w1=7.264572872337989\n",
      "SubGD iter. 357/499: loss=9.057333544503262, w0=66.02055999999997, w1=7.350284730499054\n",
      "SubGD iter. 358/499: loss=8.958924209796942, w0=66.13099999999997, w1=7.436102774139348\n",
      "SubGD iter. 359/499: loss=8.861296321716523, w0=66.24059999999997, w1=7.522053148313411\n",
      "SubGD iter. 360/499: loss=8.764542265472015, w0=66.34935999999998, w1=7.608090571695992\n",
      "SubGD iter. 361/499: loss=8.668536896177075, w0=66.45743999999998, w1=7.69429833761157\n",
      "SubGD iter. 362/499: loss=8.573128190382198, w0=66.56479999999998, w1=7.780500419356647\n",
      "SubGD iter. 363/499: loss=8.478552575529308, w0=66.67127999999998, w1=7.866716419963435\n",
      "SubGD iter. 364/499: loss=8.385028585187058, w0=66.77683999999998, w1=7.952669120517358\n",
      "SubGD iter. 365/499: loss=8.292702835958815, w0=66.88155999999998, w1=8.038268038804304\n",
      "SubGD iter. 366/499: loss=8.201450407832501, w0=66.98535999999999, w1=8.123903165140907\n",
      "SubGD iter. 367/499: loss=8.1110830930737, w0=67.08863999999998, w1=8.20947773548434\n",
      "SubGD iter. 368/499: loss=8.021327578355903, w0=67.19135999999999, w1=8.294955805313547\n",
      "SubGD iter. 369/499: loss=7.93215606510488, w0=67.29343999999999, w1=8.380424574487154\n",
      "SubGD iter. 370/499: loss=7.84368756134673, w0=67.39495999999998, w1=8.465774549426303\n",
      "SubGD iter. 371/499: loss=7.755930024658305, w0=67.49583999999999, w1=8.55105089796327\n",
      "SubGD iter. 372/499: loss=7.66893470744898, w0=67.59595999999999, w1=8.636042451306738\n",
      "SubGD iter. 373/499: loss=7.582845917822188, w0=67.69532, w1=8.721058225260572\n",
      "SubGD iter. 374/499: loss=7.497735218378873, w0=67.7932, w1=8.805791357922523\n",
      "SubGD iter. 375/499: loss=7.41416337397287, w0=67.89056, w1=8.890178097889159\n",
      "SubGD iter. 376/499: loss=7.3313196749130425, w0=67.98747999999999, w1=8.974307551891101\n",
      "SubGD iter. 377/499: loss=7.249187655035377, w0=68.08335999999998, w1=9.058475430419536\n",
      "SubGD iter. 378/499: loss=7.168039639568558, w0=68.17859999999999, w1=9.141999486724906\n",
      "SubGD iter. 379/499: loss=7.088058105550779, w0=68.27295999999998, w1=9.22539321148441\n",
      "SubGD iter. 380/499: loss=7.008976943650495, w0=68.36679999999998, w1=9.308491247734786\n",
      "SubGD iter. 381/499: loss=6.930702766748279, w0=68.45995999999998, w1=9.391223487816498\n",
      "SubGD iter. 382/499: loss=6.853310186979848, w0=68.55243999999998, w1=9.473388919359715\n",
      "SubGD iter. 383/499: loss=6.777054368163768, w0=68.64399999999998, w1=9.555037538948792\n",
      "SubGD iter. 384/499: loss=6.702047162795345, w0=68.73463999999997, w1=9.63627632467766\n",
      "SubGD iter. 385/499: loss=6.628195179151991, w0=68.82435999999997, w1=9.717258244021004\n",
      "SubGD iter. 386/499: loss=6.555459751291331, w0=68.91315999999998, w1=9.797799854271158\n",
      "SubGD iter. 387/499: loss=6.483894836126223, w0=69.00075999999997, w1=9.877930655128086\n",
      "SubGD iter. 388/499: loss=6.413769699941347, w0=69.08751999999997, w1=9.957154040081583\n",
      "SubGD iter. 389/499: loss=6.344982197444693, w0=69.17339999999997, w1=10.035963790995975\n",
      "SubGD iter. 390/499: loss=6.277427629667932, w0=69.25787999999997, w1=10.114215422127728\n",
      "SubGD iter. 391/499: loss=6.211450957024229, w0=69.34135999999997, w1=10.191951314167186\n",
      "SubGD iter. 392/499: loss=6.146716022022329, w0=69.42423999999997, w1=10.268676031430818\n",
      "SubGD iter. 393/499: loss=6.083355100936408, w0=69.50575999999997, w1=10.344784281771684\n",
      "SubGD iter. 394/499: loss=6.021507105650477, w0=69.58615999999996, w1=10.420458188708443\n",
      "SubGD iter. 395/499: loss=5.960769631559496, w0=69.66591999999996, w1=10.495510160469669\n",
      "SubGD iter. 396/499: loss=5.901286662342607, w0=69.74459999999996, w1=10.569329412526677\n",
      "SubGD iter. 397/499: loss=5.843404625755314, w0=69.82255999999997, w1=10.642349828961937\n",
      "SubGD iter. 398/499: loss=5.786659347612391, w0=69.89955999999997, w1=10.714652656019476\n",
      "SubGD iter. 399/499: loss=5.731157914438899, w0=69.97563999999997, w1=10.786175616499348\n",
      "SubGD iter. 400/499: loss=5.677050046823366, w0=70.05031999999997, w1=10.856949155578526\n",
      "SubGD iter. 401/499: loss=5.624496434786146, w0=70.12351999999997, w1=10.927221446643326\n",
      "SubGD iter. 402/499: loss=5.5733837383620575, w0=70.19575999999996, w1=10.996477222349796\n",
      "SubGD iter. 403/499: loss=5.523673568759866, w0=70.26707999999996, w1=11.064814727019849\n",
      "SubGD iter. 404/499: loss=5.475308618576619, w0=70.33735999999996, w1=11.131971587119022\n",
      "SubGD iter. 405/499: loss=5.428342761580916, w0=70.40683999999996, w1=11.198115050593296\n",
      "SubGD iter. 406/499: loss=5.382721783241583, w0=70.47535999999997, w1=11.263095556058294\n",
      "SubGD iter. 407/499: loss=5.3384100967382295, w0=70.54291999999997, w1=11.32747106930868\n",
      "SubGD iter. 408/499: loss=5.295161919734752, w0=70.60911999999996, w1=11.390969384476485\n",
      "SubGD iter. 409/499: loss=5.25329214846447, w0=70.67455999999996, w1=11.45363313094318\n",
      "SubGD iter. 410/499: loss=5.2126052278934765, w0=70.73907999999996, w1=11.51494672255987\n",
      "SubGD iter. 411/499: loss=5.173393380331892, w0=70.80211999999996, w1=11.57501956011639\n",
      "SubGD iter. 412/499: loss=5.135772301771321, w0=70.86387999999997, w1=11.634084124407888\n",
      "SubGD iter. 413/499: loss=5.099687813990066, w0=70.92459999999997, w1=11.69176331241642\n",
      "SubGD iter. 414/499: loss=5.065004491890453, w0=70.98439999999997, w1=11.747916646095991\n",
      "SubGD iter. 415/499: loss=5.031765653526254, w0=71.04291999999997, w1=11.802485007271535\n",
      "SubGD iter. 416/499: loss=5.000108970408154, w0=71.10019999999997, w1=11.855841983016544\n",
      "SubGD iter. 417/499: loss=4.969824691545875, w0=71.15635999999998, w1=11.907781829905977\n",
      "SubGD iter. 418/499: loss=4.940932042728531, w0=71.21131999999997, w1=11.95837545133734\n",
      "SubGD iter. 419/499: loss=4.9133217959696625, w0=71.26511999999997, w1=12.007588639903304\n",
      "SubGD iter. 420/499: loss=4.8870820573929965, w0=71.31771999999997, w1=12.055504350891956\n",
      "SubGD iter. 421/499: loss=4.862044864409728, w0=71.36935999999997, w1=12.101986767596374\n",
      "SubGD iter. 422/499: loss=4.838219886826345, w0=71.41979999999997, w1=12.147384225558762\n",
      "SubGD iter. 423/499: loss=4.815497229822423, w0=71.46919999999997, w1=12.191220449785048\n",
      "SubGD iter. 424/499: loss=4.793901189245052, w0=71.51755999999997, w1=12.234143204995656\n",
      "SubGD iter. 425/499: loss=4.773330875424307, w0=71.56467999999998, w1=12.275858288790689\n",
      "SubGD iter. 426/499: loss=4.753734571748075, w0=71.61083999999998, w1=12.31665455599121\n",
      "SubGD iter. 427/499: loss=4.735019486413507, w0=71.65547999999998, w1=12.356292102168835\n",
      "SubGD iter. 428/499: loss=4.71757533917595, w0=71.69855999999999, w1=12.394153507856526\n",
      "SubGD iter. 429/499: loss=4.701318292686228, w0=71.74067999999998, w1=12.431177720656056\n",
      "SubGD iter. 430/499: loss=4.685771207875057, w0=71.78191999999999, w1=12.467383829311947\n",
      "SubGD iter. 431/499: loss=4.670876134688969, w0=71.82215999999998, w1=12.502917865974267\n",
      "SubGD iter. 432/499: loss=4.6566407094968385, w0=71.86135999999998, w1=12.537356912062885\n",
      "SubGD iter. 433/499: loss=4.643167847157328, w0=71.89967999999998, w1=12.57089045678999\n",
      "SubGD iter. 434/499: loss=4.630401354622623, w0=71.93715999999998, w1=12.603166322524366\n",
      "SubGD iter. 435/499: loss=4.618310931183166, w0=71.97379999999998, w1=12.634516852773695\n",
      "SubGD iter. 436/499: loss=4.606817432555273, w0=72.00959999999998, w1=12.66488489444698\n",
      "SubGD iter. 437/499: loss=4.595978139209794, w0=72.04427999999997, w1=12.693886190990117\n",
      "SubGD iter. 438/499: loss=4.585885072788467, w0=72.07807999999997, w1=12.722092574649158\n",
      "SubGD iter. 439/499: loss=4.576363274383499, w0=72.11063999999998, w1=12.74893954541673\n",
      "SubGD iter. 440/499: loss=4.567646103334095, w0=72.14207999999998, w1=12.774560765976526\n",
      "SubGD iter. 441/499: loss=4.559509845505354, w0=72.17279999999998, w1=12.799582621239253\n",
      "SubGD iter. 442/499: loss=4.551762256855916, w0=72.20251999999998, w1=12.824057588244525\n",
      "SubGD iter. 443/499: loss=4.544413068555414, w0=72.23179999999998, w1=12.848191227531318\n",
      "SubGD iter. 444/499: loss=4.537340325706522, w0=72.26023999999998, w1=12.871607595352701\n",
      "SubGD iter. 445/499: loss=4.530700363709958, w0=72.28759999999998, w1=12.89390955856048\n",
      "SubGD iter. 446/499: loss=4.524537553714228, w0=72.31447999999999, w1=12.915667348031995\n",
      "SubGD iter. 447/499: loss=4.5186440387015026, w0=72.34067999999999, w1=12.936809652616658\n",
      "SubGD iter. 448/499: loss=4.513056164142723, w0=72.36619999999999, w1=12.957164675810454\n",
      "SubGD iter. 449/499: loss=4.5077945507176524, w0=72.39103999999999, w1=12.97696842867194\n",
      "SubGD iter. 450/499: loss=4.5027939529315635, w0=72.41519999999998, w1=12.996436390248546\n",
      "SubGD iter. 451/499: loss=4.498046438045668, w0=72.43879999999999, w1=13.015295842638533\n",
      "SubGD iter. 452/499: loss=4.493527599147317, w0=72.46187999999998, w1=13.033607380410926\n",
      "SubGD iter. 453/499: loss=4.489276275719676, w0=72.48419999999997, w1=13.050807760402897\n",
      "SubGD iter. 454/499: loss=4.48536211569249, w0=72.50595999999997, w1=13.067630756760204\n",
      "SubGD iter. 455/499: loss=4.48164478578876, w0=72.52687999999998, w1=13.083715353867266\n",
      "SubGD iter. 456/499: loss=4.4782248192648595, w0=72.54707999999998, w1=13.09911462132977\n",
      "SubGD iter. 457/499: loss=4.475009916812834, w0=72.56703999999998, w1=13.114375165363287\n",
      "SubGD iter. 458/499: loss=4.471917722341284, w0=72.58631999999997, w1=13.128749900183852\n",
      "SubGD iter. 459/499: loss=4.46907887217854, w0=72.60491999999998, w1=13.142688836337879\n",
      "SubGD iter. 460/499: loss=4.4664390559010165, w0=72.62291999999998, w1=13.155976545296546\n",
      "SubGD iter. 461/499: loss=4.463958142835401, w0=72.64059999999998, w1=13.169073268662551\n",
      "SubGD iter. 462/499: loss=4.461580990467759, w0=72.65759999999997, w1=13.181849509793082\n",
      "SubGD iter. 463/499: loss=4.459366353929052, w0=72.67411999999997, w1=13.193922614511504\n",
      "SubGD iter. 464/499: loss=4.457311663837798, w0=72.69015999999998, w1=13.205498232371177\n",
      "SubGD iter. 465/499: loss=4.455387453917455, w0=72.70575999999998, w1=13.216792519224477\n",
      "SubGD iter. 466/499: loss=4.45355542937406, w0=72.72087999999998, w1=13.22764989692633\n",
      "SubGD iter. 467/499: loss=4.451842389286966, w0=72.73575999999998, w1=13.238167558593412\n",
      "SubGD iter. 468/499: loss=4.450215061693941, w0=72.75019999999998, w1=13.248244932935428\n",
      "SubGD iter. 469/499: loss=4.448674194881216, w0=72.76439999999998, w1=13.258084419016333\n",
      "SubGD iter. 470/499: loss=4.447201129615197, w0=72.77827999999998, w1=13.267633805735993\n",
      "SubGD iter. 471/499: loss=4.445808820162603, w0=72.79167999999999, w1=13.276946926852931\n",
      "SubGD iter. 472/499: loss=4.444501252466205, w0=72.80463999999999, w1=13.285967317113949\n",
      "SubGD iter. 473/499: loss=4.4432728721770305, w0=72.81732, w1=13.294710249813976\n",
      "SubGD iter. 474/499: loss=4.442111568767093, w0=72.82943999999999, w1=13.30293640963405\n",
      "SubGD iter. 475/499: loss=4.441047921548813, w0=72.84123999999998, w1=13.310879650000425\n",
      "SubGD iter. 476/499: loss=4.440062665262712, w0=72.85243999999999, w1=13.318318731811445\n",
      "SubGD iter. 477/499: loss=4.439162167814257, w0=72.86343999999998, w1=13.325716968910484\n",
      "SubGD iter. 478/499: loss=4.438301883566388, w0=72.87415999999999, w1=13.332786493702468\n",
      "SubGD iter. 479/499: loss=4.437492971085102, w0=72.88456, w1=13.339573091631456\n",
      "SubGD iter. 480/499: loss=4.436731031755035, w0=72.89471999999999, w1=13.346097317987002\n",
      "SubGD iter. 481/499: loss=4.436013266321977, w0=72.90459999999999, w1=13.352446430676773\n",
      "SubGD iter. 482/499: loss=4.435337743831737, w0=72.91415999999998, w1=13.358582555331266\n",
      "SubGD iter. 483/499: loss=4.434700361231052, w0=72.92351999999998, w1=13.364595261528638\n",
      "SubGD iter. 484/499: loss=4.434100815399378, w0=72.93251999999998, w1=13.370144312560159\n",
      "SubGD iter. 485/499: loss=4.43355040679032, w0=72.94119999999998, w1=13.375384303136666\n",
      "SubGD iter. 486/499: loss=4.433046390440794, w0=72.94955999999998, w1=13.380453806895353\n",
      "SubGD iter. 487/499: loss=4.432572831187321, w0=72.95767999999998, w1=13.38539942183351\n",
      "SubGD iter. 488/499: loss=4.432125218048506, w0=72.96571999999998, w1=13.390037027070127\n",
      "SubGD iter. 489/499: loss=4.431699995189663, w0=72.97355999999998, w1=13.39455356255179\n",
      "SubGD iter. 490/499: loss=4.431293305367351, w0=72.98131999999998, w1=13.39906692380986\n",
      "SubGD iter. 491/499: loss=4.430895274509198, w0=72.98879999999998, w1=13.403488157157417\n",
      "SubGD iter. 492/499: loss=4.430523700880059, w0=72.99603999999998, w1=13.407717595267574\n",
      "SubGD iter. 493/499: loss=4.430175849776938, w0=73.00311999999998, w1=13.411787699075525\n",
      "SubGD iter. 494/499: loss=4.429850560292166, w0=73.00991999999998, w1=13.415526491890873\n",
      "SubGD iter. 495/499: loss=4.429554148374455, w0=73.01659999999998, w1=13.419145732180493\n",
      "SubGD iter. 496/499: loss=4.429273312023279, w0=73.02291999999998, w1=13.422517721991504\n",
      "SubGD iter. 497/499: loss=4.429018465266191, w0=73.02911999999999, w1=13.425732537940245\n",
      "SubGD iter. 498/499: loss=4.428779238661938, w0=73.03515999999999, w1=13.428863355796542\n",
      "SubGD iter. 499/499: loss=4.428549753991591, w0=73.04108, w1=13.431996520453271\n",
      "SubGD: execution time=0.134 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.2\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0.])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(\n",
    "    y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0af0322d364e6ca3645d9d688b6647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses, subgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic SubGradient Descent algorithm (SubSGD).\n",
    "            \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size=batch_size, num_batches=1):\n",
    "            # compute a stochastic gradient and loss\n",
    "            grad = compute_subgradient_mae(y_batch, tx_batch, w)\n",
    "            # update w through the stochastic gradient update\n",
    "            w = w - gamma * grad\n",
    "            # calculate loss\n",
    "            loss = compute_mae(y, tx, w)\n",
    "            # store w and loss\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "        \n",
    "        print(\"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=72.59392200210517, w0=0.7, w1=-1.0115814241869985\n",
      "SubSGD iter. 1/499: loss=71.89392200210516, w0=1.4, w1=-1.3685920512528413\n",
      "SubSGD iter. 2/499: loss=71.19392200210518, w0=2.0999999999999996, w1=-0.6728988521554239\n",
      "SubSGD iter. 3/499: loss=70.49392200210517, w0=2.8, w1=1.0031491048938759\n",
      "SubSGD iter. 4/499: loss=69.79392200210518, w0=3.5, w1=1.7245857131051727\n",
      "SubSGD iter. 5/499: loss=69.09392200210519, w0=4.2, w1=2.6099896335201302\n",
      "SubSGD iter. 6/499: loss=68.39392200210517, w0=4.9, w1=3.0028975866683516\n",
      "SubSGD iter. 7/499: loss=67.69392200210518, w0=5.6000000000000005, w1=2.7593675892014358\n",
      "SubSGD iter. 8/499: loss=66.99392200210517, w0=6.300000000000001, w1=2.1444793606736\n",
      "SubSGD iter. 9/499: loss=66.29392200210518, w0=7.000000000000001, w1=0.7305908867765016\n",
      "SubSGD iter. 10/499: loss=65.59392200210519, w0=7.700000000000001, w1=1.231025467579539\n",
      "SubSGD iter. 11/499: loss=64.89392200210517, w0=8.4, w1=2.453204774277393\n",
      "SubSGD iter. 12/499: loss=64.19392200210517, w0=9.1, w1=2.8190297097128796\n",
      "SubSGD iter. 13/499: loss=63.49392200210518, w0=9.799999999999999, w1=2.2743951520674672\n",
      "SubSGD iter. 14/499: loss=62.793922002105184, w0=10.499999999999998, w1=1.3770053741793145\n",
      "SubSGD iter. 15/499: loss=62.09392200210518, w0=11.199999999999998, w1=1.8413851722590877\n",
      "SubSGD iter. 16/499: loss=61.393922002105185, w0=11.899999999999997, w1=1.6830397233356325\n",
      "SubSGD iter. 17/499: loss=60.69392200210518, w0=12.599999999999996, w1=1.49635982717109\n",
      "SubSGD iter. 18/499: loss=59.99392200210518, w0=13.299999999999995, w1=0.04796572970381985\n",
      "SubSGD iter. 19/499: loss=59.293922002105184, w0=13.999999999999995, w1=0.09367822204767767\n",
      "SubSGD iter. 20/499: loss=58.59392200210518, w0=14.699999999999994, w1=0.4560968046701217\n",
      "SubSGD iter. 21/499: loss=57.893922002105185, w0=15.399999999999993, w1=0.9345879930150798\n",
      "SubSGD iter. 22/499: loss=57.19392200210518, w0=16.099999999999994, w1=0.4701369220704196\n",
      "SubSGD iter. 23/499: loss=56.49392200210518, w0=16.799999999999994, w1=-0.29383826297552923\n",
      "SubSGD iter. 24/499: loss=55.793922002105184, w0=17.499999999999993, w1=-0.004822037134963542\n",
      "SubSGD iter. 25/499: loss=55.09392200210518, w0=18.199999999999992, w1=0.29497358257788225\n",
      "SubSGD iter. 26/499: loss=54.393922002105185, w0=18.89999999999999, w1=0.7707248053090381\n",
      "SubSGD iter. 27/499: loss=53.6939220021052, w0=19.59999999999999, w1=1.715462030603847\n",
      "SubSGD iter. 28/499: loss=52.993922002105194, w0=20.29999999999999, w1=0.5766793839285116\n",
      "SubSGD iter. 29/499: loss=52.29392200210519, w0=20.99999999999999, w1=0.4945660633259207\n",
      "SubSGD iter. 30/499: loss=51.59392200210519, w0=21.69999999999999, w1=1.8268058520274342\n",
      "SubSGD iter. 31/499: loss=50.893922002105185, w0=22.399999999999988, w1=0.6750502564778293\n",
      "SubSGD iter. 32/499: loss=50.1939220021052, w0=23.099999999999987, w1=0.5224530968014127\n",
      "SubSGD iter. 33/499: loss=49.49392200210519, w0=23.799999999999986, w1=1.4781555625421405\n",
      "SubSGD iter. 34/499: loss=48.79392200210519, w0=24.499999999999986, w1=0.6976087197551983\n",
      "SubSGD iter. 35/499: loss=48.09392200210519, w0=25.199999999999985, w1=-0.5306106005046267\n",
      "SubSGD iter. 36/499: loss=47.393922002105185, w0=25.899999999999984, w1=-0.4995859494065723\n",
      "SubSGD iter. 37/499: loss=46.6939220021052, w0=26.599999999999984, w1=0.6233355511956177\n",
      "SubSGD iter. 38/499: loss=45.99392200210519, w0=27.299999999999983, w1=-0.1376413384942382\n",
      "SubSGD iter. 39/499: loss=45.294312722463125, w0=27.999999999999982, w1=-1.0576174945240377\n",
      "SubSGD iter. 40/499: loss=44.59402451169484, w0=28.69999999999998, w1=-0.3770934719762835\n",
      "SubSGD iter. 41/499: loss=43.89392200210519, w0=29.39999999999998, w1=0.727660307056923\n",
      "SubSGD iter. 42/499: loss=43.1939220021052, w0=30.09999999999998, w1=0.9749944966334865\n",
      "SubSGD iter. 43/499: loss=42.49394733296563, w0=30.79999999999998, w1=0.4130362813546945\n",
      "SubSGD iter. 44/499: loss=41.7939220021052, w0=31.49999999999998, w1=0.9630376800608325\n",
      "SubSGD iter. 45/499: loss=41.094157619253004, w0=32.19999999999998, w1=0.5238271807375768\n",
      "SubSGD iter. 46/499: loss=40.39589514444965, w0=32.899999999999984, w1=-0.38844856567285724\n",
      "SubSGD iter. 47/499: loss=39.69658074532636, w0=33.59999999999999, w1=-0.4439041950631839\n",
      "SubSGD iter. 48/499: loss=38.99831837660231, w0=34.29999999999999, w1=-0.7372623227879802\n",
      "SubSGD iter. 49/499: loss=38.30288021450815, w0=34.99999999999999, w1=-1.3884060464650085\n",
      "SubSGD iter. 50/499: loss=37.598545769220486, w0=35.699999999999996, w1=-0.2709298557307187\n",
      "SubSGD iter. 51/499: loss=36.89816769200266, w0=36.4, w1=0.07618307405980518\n",
      "SubSGD iter. 52/499: loss=36.195934276666655, w0=37.1, w1=1.077789711016607\n",
      "SubSGD iter. 53/499: loss=35.50068974777716, w0=37.800000000000004, w1=0.07571263017898233\n",
      "SubSGD iter. 54/499: loss=34.804350475947, w0=38.50000000000001, w1=-0.19313542156724328\n",
      "SubSGD iter. 55/499: loss=34.10346236817524, w0=39.20000000000001, w1=0.18935914773092272\n",
      "SubSGD iter. 56/499: loss=33.40149608955132, w0=39.90000000000001, w1=0.75372916644068\n",
      "SubSGD iter. 57/499: loss=32.73355650520684, w0=40.600000000000016, w1=-0.9896819169552249\n",
      "SubSGD iter. 58/499: loss=32.067618168894064, w0=41.30000000000002, w1=-1.5720228176205706\n",
      "SubSGD iter. 59/499: loss=31.391167490379086, w0=42.00000000000002, w1=-1.6866965374537692\n",
      "SubSGD iter. 60/499: loss=30.665345625909325, w0=42.700000000000024, w1=-0.88358026801846\n",
      "SubSGD iter. 61/499: loss=30.000146776190853, w0=43.40000000000003, w1=-1.1727039018963445\n",
      "SubSGD iter. 62/499: loss=29.411055292467143, w0=44.10000000000003, w1=-2.13611900916038\n",
      "SubSGD iter. 63/499: loss=28.68247036300207, w0=44.80000000000003, w1=-1.504879112184412\n",
      "SubSGD iter. 64/499: loss=27.994540210051554, w0=45.500000000000036, w1=-1.2655027644660777\n",
      "SubSGD iter. 65/499: loss=27.392297364588046, w0=46.20000000000004, w1=-1.7157001008996453\n",
      "SubSGD iter. 66/499: loss=26.607375995516325, w0=46.90000000000004, w1=-0.6496582047410313\n",
      "SubSGD iter. 67/499: loss=26.056886604612732, w0=47.600000000000044, w1=-1.4074836960251875\n",
      "SubSGD iter. 68/499: loss=25.29155086455445, w0=48.30000000000005, w1=-0.5749184870690021\n",
      "SubSGD iter. 69/499: loss=24.607246721458328, w0=49.00000000000005, w1=-0.30002972122023625\n",
      "SubSGD iter. 70/499: loss=23.90160054113697, w0=49.70000000000005, w1=0.1283148322036874\n",
      "SubSGD iter. 71/499: loss=23.132945935971467, w0=50.400000000000055, w1=1.0229123871133032\n",
      "SubSGD iter. 72/499: loss=22.54444582483908, w0=51.10000000000006, w1=0.6424551616972893\n",
      "SubSGD iter. 73/499: loss=21.91893455315581, w0=51.80000000000006, w1=0.6241691848401069\n",
      "SubSGD iter. 74/499: loss=21.146168867115264, w0=52.500000000000064, w1=1.4474588392409027\n",
      "SubSGD iter. 75/499: loss=21.667744940509934, w0=51.80000000000006, w1=2.3740612046373935\n",
      "SubSGD iter. 76/499: loss=21.037648788493378, w0=52.500000000000064, w1=2.174881000467664\n",
      "SubSGD iter. 77/499: loss=20.359532299136294, w0=53.20000000000007, w1=2.421847583261087\n",
      "SubSGD iter. 78/499: loss=19.88401262479555, w0=53.90000000000007, w1=1.5591093573409573\n",
      "SubSGD iter. 79/499: loss=19.087227479823138, w0=54.60000000000007, w1=2.4790890307165077\n",
      "SubSGD iter. 80/499: loss=18.496336579261396, w0=55.300000000000075, w1=2.3717208471508053\n",
      "SubSGD iter. 81/499: loss=17.74395882157986, w0=56.00000000000008, w1=3.0658430091993205\n",
      "SubSGD iter. 82/499: loss=17.441522446929998, w0=56.70000000000008, w1=1.953299867893299\n",
      "SubSGD iter. 83/499: loss=16.875953295442713, w0=57.400000000000084, w1=2.006941141570516\n",
      "SubSGD iter. 84/499: loss=16.68382174159884, w0=58.10000000000009, w1=1.1172799269106322\n",
      "SubSGD iter. 85/499: loss=16.116040072115826, w0=58.80000000000009, w1=1.3151779887537063\n",
      "SubSGD iter. 86/499: loss=15.227980240409568, w0=59.50000000000009, w1=2.3002513693607174\n",
      "SubSGD iter. 87/499: loss=14.869483135755933, w0=60.200000000000095, w1=2.0373014950633928\n",
      "SubSGD iter. 88/499: loss=14.986831160708837, w0=59.50000000000009, w1=2.9220821288600805\n",
      "SubSGD iter. 89/499: loss=14.317124593995464, w0=60.200000000000095, w1=3.3730760539924427\n",
      "SubSGD iter. 90/499: loss=14.636521517456224, w0=59.50000000000009, w1=3.9501669383857076\n",
      "SubSGD iter. 91/499: loss=13.97834581554892, w0=60.200000000000095, w1=4.34122295253454\n",
      "SubSGD iter. 92/499: loss=13.387113633619846, w0=60.9000000000001, w1=4.551989350825298\n",
      "SubSGD iter. 93/499: loss=12.64947773607246, w0=61.6000000000001, w1=5.2196432379246875\n",
      "SubSGD iter. 94/499: loss=12.105060871248957, w0=62.300000000000104, w1=5.343385228189937\n",
      "SubSGD iter. 95/499: loss=11.958263257428257, w0=63.00000000000011, w1=4.572489571655453\n",
      "SubSGD iter. 96/499: loss=11.364696067063083, w0=63.70000000000011, w1=4.946077636830229\n",
      "SubSGD iter. 97/499: loss=11.01036651977182, w0=64.4000000000001, w1=4.853844526341836\n",
      "SubSGD iter. 98/499: loss=10.998555436385457, w0=65.10000000000011, w1=4.20714166704495\n",
      "SubSGD iter. 99/499: loss=11.08488567919145, w0=65.80000000000011, w1=3.5477613772475283\n",
      "SubSGD iter. 100/499: loss=10.983837139340068, w0=65.10000000000011, w1=4.233444315980747\n",
      "SubSGD iter. 101/499: loss=10.85305787588454, w0=65.80000000000011, w1=3.929870323746981\n",
      "SubSGD iter. 102/499: loss=10.530575059273977, w0=66.50000000000011, w1=4.01117415035664\n",
      "SubSGD iter. 103/499: loss=10.7286160169061, w0=65.80000000000011, w1=4.138711948965983\n",
      "SubSGD iter. 104/499: loss=10.568256924030052, w0=66.50000000000011, w1=3.950853238147266\n",
      "SubSGD iter. 105/499: loss=10.569378806295084, w0=65.80000000000011, w1=4.410138704813869\n",
      "SubSGD iter. 106/499: loss=10.370798245654374, w0=65.10000000000011, w1=5.387709930968874\n",
      "SubSGD iter. 107/499: loss=10.550939633563523, w0=64.4000000000001, w1=5.828912723739473\n",
      "SubSGD iter. 108/499: loss=9.903354146580233, w0=65.10000000000011, w1=6.371439678102688\n",
      "SubSGD iter. 109/499: loss=9.092298669714982, w0=65.80000000000011, w1=7.327142143843416\n",
      "SubSGD iter. 110/499: loss=8.439447277569567, w0=66.50000000000011, w1=7.956830535698863\n",
      "SubSGD iter. 111/499: loss=7.717101780762093, w0=67.20000000000012, w1=8.811339255980311\n",
      "SubSGD iter. 112/499: loss=6.755820557164483, w0=67.90000000000012, w1=10.509070202365002\n",
      "SubSGD iter. 113/499: loss=7.3165658764594586, w0=67.20000000000012, w1=9.995495872035901\n",
      "SubSGD iter. 114/499: loss=6.955681798416497, w0=67.90000000000012, w1=9.862392404919229\n",
      "SubSGD iter. 115/499: loss=6.492931875780114, w0=68.60000000000012, w1=10.160035477645764\n",
      "SubSGD iter. 116/499: loss=5.8944538423970325, w0=69.30000000000013, w1=10.975010661972117\n",
      "SubSGD iter. 117/499: loss=5.4181087061956426, w0=70.00000000000013, w1=11.593819449087153\n",
      "SubSGD iter. 118/499: loss=4.877561948883067, w0=70.70000000000013, w1=13.429456706461359\n",
      "SubSGD iter. 119/499: loss=4.7166972784423695, w0=71.40000000000013, w1=12.736601777949764\n",
      "SubSGD iter. 120/499: loss=4.877981611649105, w0=70.70000000000013, w1=13.4097912055447\n",
      "SubSGD iter. 121/499: loss=5.212706377138346, w0=70.00000000000013, w1=14.518435839110616\n",
      "SubSGD iter. 122/499: loss=5.081066013045735, w0=70.70000000000013, w1=15.299782411573759\n",
      "SubSGD iter. 123/499: loss=5.317722650369895, w0=70.00000000000013, w1=15.172193408690966\n",
      "SubSGD iter. 124/499: loss=5.165642520430312, w0=70.70000000000013, w1=15.64233245010729\n",
      "SubSGD iter. 125/499: loss=5.0035721226798335, w0=71.40000000000013, w1=15.76607444037254\n",
      "SubSGD iter. 126/499: loss=5.347793440863178, w0=70.70000000000013, w1=16.253597245692944\n",
      "SubSGD iter. 127/499: loss=5.2348219778548755, w0=71.40000000000013, w1=16.469322653138253\n",
      "SubSGD iter. 128/499: loss=5.79940226993353, w0=70.70000000000013, w1=17.424702194223887\n",
      "SubSGD iter. 129/499: loss=5.504052273950238, w0=71.40000000000013, w1=17.150405737660716\n",
      "SubSGD iter. 130/499: loss=5.355096930390459, w0=72.10000000000014, w1=17.082887105895527\n",
      "SubSGD iter. 131/499: loss=5.107216593600365, w0=71.40000000000013, w1=16.100159278878404\n",
      "SubSGD iter. 132/499: loss=5.06001519508678, w0=72.10000000000014, w1=16.33953562659674\n",
      "SubSGD iter. 133/499: loss=4.7821993740957645, w0=72.80000000000014, w1=15.71416913450567\n",
      "SubSGD iter. 134/499: loss=4.5635829816305735, w0=73.50000000000014, w1=14.862303868345865\n",
      "SubSGD iter. 135/499: loss=4.63865641879589, w0=72.80000000000014, w1=15.179288077334974\n",
      "SubSGD iter. 136/499: loss=4.484034209767165, w0=73.50000000000014, w1=14.365198735327938\n",
      "SubSGD iter. 137/499: loss=4.710218765925155, w0=72.80000000000014, w1=15.462499972988988\n",
      "SubSGD iter. 138/499: loss=4.541341897005719, w0=72.10000000000014, w1=14.134724061714426\n",
      "SubSGD iter. 139/499: loss=4.723251242732691, w0=71.40000000000013, w1=14.473181752538574\n",
      "SubSGD iter. 140/499: loss=4.983307804300737, w0=70.70000000000013, w1=14.811730720619234\n",
      "SubSGD iter. 141/499: loss=4.889848489066183, w0=71.40000000000013, w1=15.343949618463931\n",
      "SubSGD iter. 142/499: loss=4.756492073056082, w0=72.10000000000014, w1=15.36244592960998\n",
      "SubSGD iter. 143/499: loss=5.017806718240581, w0=71.40000000000013, w1=15.814215043304651\n",
      "SubSGD iter. 144/499: loss=4.6716830391291095, w0=72.10000000000014, w1=15.000125701297616\n",
      "SubSGD iter. 145/499: loss=4.686077284767459, w0=72.80000000000014, w1=15.37134412544302\n",
      "SubSGD iter. 146/499: loss=4.566634464340023, w0=72.10000000000014, w1=14.371977371607722\n",
      "SubSGD iter. 147/499: loss=4.691854919847933, w0=71.40000000000013, w1=14.198612510858304\n",
      "SubSGD iter. 148/499: loss=4.652146428636646, w0=72.10000000000014, w1=14.904701199283103\n",
      "SubSGD iter. 149/499: loss=4.4785700228218195, w0=72.80000000000014, w1=14.275187416608405\n",
      "SubSGD iter. 150/499: loss=4.4450001840036615, w0=73.50000000000014, w1=13.105622597154904\n",
      "SubSGD iter. 151/499: loss=4.546721223893737, w0=72.80000000000014, w1=12.411084247343613\n",
      "SubSGD iter. 152/499: loss=4.6993806873665855, w0=72.10000000000014, w1=12.062225221610449\n",
      "SubSGD iter. 153/499: loss=4.688302470197693, w0=71.40000000000013, w1=12.983301390499781\n",
      "SubSGD iter. 154/499: loss=4.899793647629923, w0=70.70000000000013, w1=13.011314456870615\n",
      "SubSGD iter. 155/499: loss=4.662103799422701, w0=71.40000000000013, w1=13.671176575573076\n",
      "SubSGD iter. 156/499: loss=4.550739697368863, w0=72.10000000000014, w1=12.908129968635501\n",
      "SubSGD iter. 157/499: loss=4.496983204949394, w0=72.80000000000014, w1=14.423353611642447\n",
      "SubSGD iter. 158/499: loss=4.569077295562157, w0=72.10000000000014, w1=14.39183113061461\n",
      "SubSGD iter. 159/499: loss=4.735960778611731, w0=71.40000000000013, w1=14.564200697951614\n",
      "SubSGD iter. 160/499: loss=4.677280680288809, w0=72.10000000000014, w1=15.026591546315688\n",
      "SubSGD iter. 161/499: loss=4.71863831976191, w0=72.80000000000014, w1=15.493188916590054\n",
      "SubSGD iter. 162/499: loss=4.684013919100857, w0=72.10000000000014, w1=15.058081827178933\n",
      "SubSGD iter. 163/499: loss=4.7190575379317, w0=71.40000000000013, w1=14.440830127548207\n",
      "SubSGD iter. 164/499: loss=4.953788363498421, w0=70.70000000000013, w1=14.626167653957932\n",
      "SubSGD iter. 165/499: loss=5.181766776660535, w0=70.00000000000013, w1=14.218924464413945\n",
      "SubSGD iter. 166/499: loss=5.103457912376382, w0=70.70000000000013, w1=15.395953521466431\n",
      "SubSGD iter. 167/499: loss=5.1139543697997025, w0=71.40000000000013, w1=16.120877020601938\n",
      "SubSGD iter. 168/499: loss=5.107675648209172, w0=72.10000000000014, w1=16.469016202383475\n",
      "SubSGD iter. 169/499: loss=4.921901104554552, w0=71.40000000000013, w1=15.470156304261815\n",
      "SubSGD iter. 170/499: loss=4.522800556249094, w0=72.10000000000014, w1=13.267827452717047\n",
      "SubSGD iter. 171/499: loss=4.7098696031800715, w0=71.40000000000013, w1=14.365712182506845\n",
      "SubSGD iter. 172/499: loss=4.516263035956232, w0=72.10000000000014, w1=13.651859818231765\n",
      "SubSGD iter. 173/499: loss=4.45270772643235, w0=72.80000000000014, w1=13.991790763848526\n",
      "SubSGD iter. 174/499: loss=4.5284460358883285, w0=72.10000000000014, w1=13.169416785621618\n",
      "SubSGD iter. 175/499: loss=4.828403107407552, w0=71.40000000000013, w1=12.111416566151757\n",
      "SubSGD iter. 176/499: loss=4.583278410653177, w0=72.10000000000014, w1=12.649479509013132\n",
      "SubSGD iter. 177/499: loss=4.456337804235837, w0=72.80000000000014, w1=13.073521218948498\n",
      "SubSGD iter. 178/499: loss=4.429808642870842, w0=73.50000000000014, w1=13.44951952543241\n",
      "SubSGD iter. 179/499: loss=4.513062533529616, w0=74.20000000000014, w1=13.051785249769294\n",
      "SubSGD iter. 180/499: loss=4.4461190354730755, w0=73.50000000000014, w1=13.090129034776153\n",
      "SubSGD iter. 181/499: loss=4.500619920920802, w0=74.20000000000014, w1=13.817464719168617\n",
      "SubSGD iter. 182/499: loss=4.467711264065601, w0=73.50000000000014, w1=12.863848497662872\n",
      "SubSGD iter. 183/499: loss=4.515295550496756, w0=74.20000000000014, w1=14.050362383424893\n",
      "SubSGD iter. 184/499: loss=4.429992760759254, w0=73.50000000000014, w1=13.437664350243823\n",
      "SubSGD iter. 185/499: loss=4.505690995600369, w0=74.20000000000014, w1=13.913458966361667\n",
      "SubSGD iter. 186/499: loss=4.487358922757339, w0=73.50000000000014, w1=14.391389207293427\n",
      "SubSGD iter. 187/499: loss=4.44801267168568, w0=72.80000000000014, w1=13.91575840712643\n",
      "SubSGD iter. 188/499: loss=4.537119635273276, w0=73.50000000000014, w1=12.418424588176373\n",
      "SubSGD iter. 189/499: loss=4.4380148290904575, w0=72.80000000000014, w1=13.553335838887923\n",
      "SubSGD iter. 190/499: loss=4.515603898007507, w0=72.10000000000014, w1=13.583087437772912\n",
      "SubSGD iter. 191/499: loss=4.439235049568826, w0=72.80000000000014, w1=13.688939215294878\n",
      "SubSGD iter. 192/499: loss=4.482809008084783, w0=73.50000000000014, w1=14.355387502050759\n",
      "SubSGD iter. 193/499: loss=4.500067631788546, w0=74.20000000000014, w1=13.804739925441806\n",
      "SubSGD iter. 194/499: loss=4.65501255960543, w0=74.90000000000015, w1=14.158530934241353\n",
      "SubSGD iter. 195/499: loss=4.497118290758214, w0=74.20000000000014, w1=13.72525893104605\n",
      "SubSGD iter. 196/499: loss=4.661652687772486, w0=74.90000000000015, w1=14.227779840652408\n",
      "SubSGD iter. 197/499: loss=4.600160880651162, w0=74.20000000000014, w1=14.713114379424917\n",
      "SubSGD iter. 198/499: loss=4.644616085038741, w0=74.90000000000015, w1=14.02647027068482\n",
      "SubSGD iter. 199/499: loss=4.865456721192427, w0=75.60000000000015, w1=14.294619971135331\n",
      "SubSGD iter. 200/499: loss=4.694755389495534, w0=74.90000000000015, w1=14.498250477694963\n",
      "SubSGD iter. 201/499: loss=4.925903799509069, w0=75.60000000000015, w1=14.74402666988038\n",
      "SubSGD iter. 202/499: loss=4.895966716191274, w0=74.90000000000015, w1=15.476129304672158\n",
      "SubSGD iter. 203/499: loss=5.344704591625142, w0=75.60000000000015, w1=16.342096402747185\n",
      "SubSGD iter. 204/499: loss=5.092159984024265, w0=74.90000000000015, w1=16.126370995301876\n",
      "SubSGD iter. 205/499: loss=5.2675521003549965, w0=74.20000000000014, w1=16.904117300375027\n",
      "SubSGD iter. 206/499: loss=5.45582095894246, w0=74.90000000000015, w1=17.087665357359747\n",
      "SubSGD iter. 207/499: loss=5.1477077140214185, w0=74.20000000000014, w1=16.60651990352351\n",
      "SubSGD iter. 208/499: loss=5.010578175462799, w0=73.50000000000014, w1=16.395996115338228\n",
      "SubSGD iter. 209/499: loss=5.11234362008418, w0=74.20000000000014, w1=16.51509393810615\n",
      "SubSGD iter. 210/499: loss=4.885237218542244, w0=73.50000000000014, w1=16.047046498186628\n",
      "SubSGD iter. 211/499: loss=5.208108381386125, w0=72.80000000000014, w1=16.883106279573454\n",
      "SubSGD iter. 212/499: loss=5.211446286509869, w0=73.50000000000014, w1=16.89891384248613\n",
      "SubSGD iter. 213/499: loss=4.925404386741819, w0=72.80000000000014, w1=16.1515664697921\n",
      "SubSGD iter. 214/499: loss=5.121882250393999, w0=72.10000000000014, w1=16.506667759425063\n",
      "SubSGD iter. 215/499: loss=5.3196090795783295, w0=72.80000000000014, w1=17.142470794707812\n",
      "SubSGD iter. 216/499: loss=5.036728043140968, w0=73.50000000000014, w1=16.46469371234732\n",
      "SubSGD iter. 217/499: loss=5.184066716715536, w0=74.20000000000014, w1=16.69856204819715\n",
      "SubSGD iter. 218/499: loss=5.372331269394365, w0=74.90000000000015, w1=16.885832460336147\n",
      "SubSGD iter. 219/499: loss=5.490141827771828, w0=74.20000000000014, w1=17.413732982887286\n",
      "SubSGD iter. 220/499: loss=5.269309081214087, w0=74.90000000000015, w1=16.623264133200692\n",
      "SubSGD iter. 221/499: loss=5.668348409815705, w0=75.60000000000015, w1=17.18932574125705\n",
      "SubSGD iter. 222/499: loss=5.566290540272365, w0=74.90000000000015, w1=17.34276148581022\n",
      "SubSGD iter. 223/499: loss=5.407444281035542, w0=74.20000000000014, w1=17.229764588897407\n",
      "SubSGD iter. 224/499: loss=5.074674580744828, w0=74.90000000000015, w1=16.073747148202763\n",
      "SubSGD iter. 225/499: loss=5.032723822890935, w0=75.60000000000015, w1=15.272372863174393\n",
      "SubSGD iter. 226/499: loss=4.896218842014332, w0=74.90000000000015, w1=15.477081196885843\n",
      "SubSGD iter. 227/499: loss=4.67173312405051, w0=74.20000000000014, w1=15.07285406844327\n",
      "SubSGD iter. 228/499: loss=4.510481598655731, w0=73.50000000000014, w1=14.555470135581096\n",
      "SubSGD iter. 229/499: loss=4.834278681189186, w0=72.80000000000014, w1=15.880815887193785\n",
      "SubSGD iter. 230/499: loss=4.508928587859802, w0=73.50000000000014, w1=14.545109020934007\n",
      "SubSGD iter. 231/499: loss=4.524282300886544, w0=74.20000000000014, w1=14.152534829976773\n",
      "SubSGD iter. 232/499: loss=4.4776801324640925, w0=73.50000000000014, w1=14.313283704715042\n",
      "SubSGD iter. 233/499: loss=4.494141947415145, w0=74.20000000000014, w1=13.54725262059715\n",
      "SubSGD iter. 234/499: loss=4.647828383116114, w0=74.90000000000015, w1=14.071825468664398\n",
      "SubSGD iter. 235/499: loss=4.854048314348956, w0=75.60000000000015, w1=14.170307160661205\n",
      "SubSGD iter. 236/499: loss=5.188205704286085, w0=76.30000000000015, w1=14.78509096602628\n",
      "SubSGD iter. 237/499: loss=4.916436482391397, w0=75.60000000000015, w1=14.685506720074082\n",
      "SubSGD iter. 238/499: loss=4.754949164113947, w0=74.90000000000015, w1=14.860660269471598\n",
      "SubSGD iter. 239/499: loss=4.90298140814737, w0=75.60000000000015, w1=14.597328846953223\n",
      "SubSGD iter. 240/499: loss=4.63552432375286, w0=74.90000000000015, w1=13.863010309538808\n",
      "SubSGD iter. 241/499: loss=4.498974593960012, w0=74.20000000000014, w1=13.777956547993558\n",
      "SubSGD iter. 242/499: loss=4.631271342219215, w0=74.90000000000015, w1=13.747107780281313\n",
      "SubSGD iter. 243/499: loss=4.50072184609041, w0=74.20000000000014, w1=13.250647269336973\n",
      "SubSGD iter. 244/499: loss=4.633392259948353, w0=74.90000000000015, w1=13.810251872557489\n",
      "SubSGD iter. 245/499: loss=4.93959168814784, w0=75.60000000000015, w1=14.823850788824462\n",
      "SubSGD iter. 246/499: loss=4.742323048761873, w0=74.90000000000015, w1=14.792473485265496\n",
      "SubSGD iter. 247/499: loss=4.885019230263871, w0=75.60000000000015, w1=14.466748493887495\n",
      "SubSGD iter. 248/499: loss=4.718123728487346, w0=74.90000000000015, w1=14.651812779280366\n",
      "SubSGD iter. 249/499: loss=4.929673704008252, w0=75.60000000000015, w1=14.76649254090629\n",
      "SubSGD iter. 250/499: loss=5.273987177265447, w0=76.30000000000015, w1=15.237312961844248\n",
      "SubSGD iter. 251/499: loss=5.223252528770785, w0=75.60000000000015, w1=15.970492571627936\n",
      "SubSGD iter. 252/499: loss=4.865767402210471, w0=74.90000000000015, w1=15.359283159589248\n",
      "SubSGD iter. 253/499: loss=4.700186809299459, w0=74.20000000000014, w1=15.197672336817277\n",
      "SubSGD iter. 254/499: loss=4.989124536053204, w0=74.90000000000015, w1=15.803707767088955\n",
      "SubSGD iter. 255/499: loss=4.984713905960896, w0=75.60000000000015, w1=15.057240353868588\n",
      "SubSGD iter. 256/499: loss=5.105620840348715, w0=76.30000000000015, w1=14.050109049299467\n",
      "SubSGD iter. 257/499: loss=5.409354836440431, w0=77.00000000000016, w1=13.542415379217887\n",
      "SubSGD iter. 258/499: loss=5.7981138445526375, w0=77.70000000000016, w1=13.937992539483973\n",
      "SubSGD iter. 259/499: loss=5.413428336933843, w0=77.00000000000016, w1=13.784176204138218\n",
      "SubSGD iter. 260/499: loss=5.09064225108463, w0=76.30000000000015, w1=13.528917790676868\n",
      "SubSGD iter. 261/499: loss=4.913492457376613, w0=75.60000000000015, w1=12.464330826513542\n",
      "SubSGD iter. 262/499: loss=5.191384473305909, w0=76.30000000000015, w1=12.292032878943322\n",
      "SubSGD iter. 263/499: loss=4.941718362732902, w0=75.60000000000015, w1=12.284938334736706\n",
      "SubSGD iter. 264/499: loss=4.668199184962759, w0=74.90000000000015, w1=12.826113002894601\n",
      "SubSGD iter. 265/499: loss=5.051978997372718, w0=75.60000000000015, w1=11.748222382721734\n",
      "SubSGD iter. 266/499: loss=5.414200016000498, w0=76.30000000000015, w1=11.277984788306314\n",
      "SubSGD iter. 267/499: loss=5.697146127678344, w0=77.00000000000016, w1=11.282587095218378\n",
      "SubSGD iter. 268/499: loss=5.432843903013889, w0=76.30000000000015, w1=11.212054765256726\n",
      "SubSGD iter. 269/499: loss=5.861577279940135, w0=77.00000000000016, w1=10.711246203022831\n",
      "SubSGD iter. 270/499: loss=5.695006974190549, w0=76.30000000000015, w1=10.435038986983706\n",
      "SubSGD iter. 271/499: loss=5.125842608129204, w0=75.60000000000015, w1=11.469005560427933\n",
      "SubSGD iter. 272/499: loss=5.268427603369548, w0=76.30000000000015, w1=11.87562384731407\n",
      "SubSGD iter. 273/499: loss=5.29437807458588, w0=75.60000000000015, w1=10.94470421349336\n",
      "SubSGD iter. 274/499: loss=5.35676002785235, w0=76.30000000000015, w1=11.493044806383562\n",
      "SubSGD iter. 275/499: loss=5.048616854630981, w0=75.60000000000015, w1=11.761892858129787\n",
      "SubSGD iter. 276/499: loss=5.169193338282474, w0=76.30000000000015, w1=12.439413451680851\n",
      "SubSGD iter. 277/499: loss=5.409590770154508, w0=77.00000000000016, w1=13.583934905010743\n",
      "SubSGD iter. 278/499: loss=5.807425522600163, w0=77.70000000000016, w1=14.093632406287478\n",
      "SubSGD iter. 279/499: loss=5.416257181392498, w0=77.00000000000016, w1=13.159733772709513\n",
      "SubSGD iter. 280/499: loss=5.155525101524595, w0=76.30000000000015, w1=12.542148195603879\n",
      "SubSGD iter. 281/499: loss=5.422761215393274, w0=77.00000000000016, w1=13.02149909978553\n",
      "SubSGD iter. 282/499: loss=5.80297091126265, w0=77.70000000000016, w1=14.022637599528176\n",
      "SubSGD iter. 283/499: loss=6.289072529325143, w0=78.40000000000016, w1=14.718330798625594\n",
      "SubSGD iter. 284/499: loss=5.7861870939585325, w0=77.70000000000016, w1=13.221444644321734\n",
      "SubSGD iter. 285/499: loss=5.438150961469898, w0=77.00000000000016, w1=14.201540686484618\n",
      "SubSGD iter. 286/499: loss=5.825876517546806, w0=77.70000000000016, w1=14.327529884202812\n",
      "SubSGD iter. 287/499: loss=5.50707227789671, w0=77.00000000000016, w1=14.793440837971616\n",
      "SubSGD iter. 288/499: loss=5.812784370635593, w0=77.70000000000016, w1=14.169032370766628\n",
      "SubSGD iter. 289/499: loss=5.4154275011351976, w0=77.00000000000016, w1=13.839354603257416\n",
      "SubSGD iter. 290/499: loss=5.830476139171716, w0=77.70000000000016, w1=14.377603826406892\n",
      "SubSGD iter. 291/499: loss=5.40965851164614, w0=77.00000000000016, w1=13.448595337427543\n",
      "SubSGD iter. 292/499: loss=5.784876468835052, w0=77.70000000000016, w1=13.576091615624017\n",
      "SubSGD iter. 293/499: loss=5.453271502086663, w0=77.00000000000016, w1=14.366892730233793\n",
      "SubSGD iter. 294/499: loss=5.846281105396122, w0=77.70000000000016, w1=14.531685641392283\n",
      "SubSGD iter. 295/499: loss=6.342477432824723, w0=78.40000000000016, w1=15.115661145351009\n",
      "SubSGD iter. 296/499: loss=5.926239396739524, w0=77.70000000000016, w1=15.110099365153587\n",
      "SubSGD iter. 297/499: loss=6.23504377684441, w0=78.40000000000016, w1=14.121902114328472\n",
      "SubSGD iter. 298/499: loss=6.67989172229971, w0=79.10000000000016, w1=13.08705100802533\n",
      "SubSGD iter. 299/499: loss=6.225168813855446, w0=78.40000000000016, w1=12.751257775585996\n",
      "SubSGD iter. 300/499: loss=5.966496903101215, w0=77.70000000000016, w1=11.589061765444766\n",
      "SubSGD iter. 301/499: loss=6.315543299483038, w0=78.40000000000016, w1=11.86815766447318\n",
      "SubSGD iter. 302/499: loss=6.715771991075386, w0=79.10000000000016, w1=12.32765973445999\n",
      "SubSGD iter. 303/499: loss=6.327821950831399, w0=78.40000000000016, w1=11.78391091960946\n",
      "SubSGD iter. 304/499: loss=5.934080874871684, w0=77.70000000000016, w1=11.759286759557947\n",
      "SubSGD iter. 305/499: loss=5.58450089240048, w0=77.00000000000016, w1=11.778343531990567\n",
      "SubSGD iter. 306/499: loss=5.8450396239956826, w0=77.70000000000016, w1=12.36220431662026\n",
      "SubSGD iter. 307/499: loss=6.220492532948985, w0=78.40000000000016, w1=12.834043549128204\n",
      "SubSGD iter. 308/499: loss=5.803717156575358, w0=77.70000000000016, w1=14.035009067259127\n",
      "SubSGD iter. 309/499: loss=5.425255332042017, w0=77.00000000000016, w1=12.979400160310437\n",
      "SubSGD iter. 310/499: loss=5.793357711182769, w0=77.70000000000016, w1=13.008098993461285\n",
      "SubSGD iter. 311/499: loss=5.423469728822002, w0=77.00000000000016, w1=13.009176841504953\n",
      "SubSGD iter. 312/499: loss=5.094068166478949, w0=76.30000000000015, w1=13.798549516091825\n",
      "SubSGD iter. 313/499: loss=4.854285764678565, w0=75.60000000000015, w1=12.977634612969158\n",
      "SubSGD iter. 314/499: loss=5.110551647865567, w0=76.30000000000015, w1=14.12215606629905\n",
      "SubSGD iter. 315/499: loss=5.412683785282841, w0=77.00000000000016, w1=13.268446560087302\n",
      "SubSGD iter. 316/499: loss=5.092036889835708, w0=76.30000000000015, w1=13.720533175945109\n",
      "SubSGD iter. 317/499: loss=5.412974306138862, w0=77.00000000000016, w1=13.76978715506991\n",
      "SubSGD iter. 318/499: loss=5.134086663173196, w0=76.30000000000015, w1=12.72896748116725\n",
      "SubSGD iter. 319/499: loss=5.429569120565439, w0=77.00000000000016, w1=12.913748581280661\n",
      "SubSGD iter. 320/499: loss=5.097561349623028, w0=76.30000000000015, w1=13.893844623443545\n",
      "SubSGD iter. 321/499: loss=5.439361181627923, w0=77.00000000000016, w1=14.21604333492013\n",
      "SubSGD iter. 322/499: loss=5.149791041800495, w0=76.30000000000015, w1=14.512697845037891\n",
      "SubSGD iter. 323/499: loss=5.4103411011487434, w0=77.00000000000016, w1=13.649441632465921\n",
      "SubSGD iter. 324/499: loss=5.800046117654219, w0=77.70000000000016, w1=13.97248676573806\n",
      "SubSGD iter. 325/499: loss=5.4208338552958315, w0=77.00000000000016, w1=13.954724603563353\n",
      "SubSGD iter. 326/499: loss=5.783818681890059, w0=77.70000000000016, w1=13.465669491022222\n",
      "SubSGD iter. 327/499: loss=5.525732307311939, w0=77.00000000000016, w1=12.096038871962417\n",
      "SubSGD iter. 328/499: loss=5.186203239373482, w0=76.30000000000015, w1=12.324914580510157\n",
      "SubSGD iter. 329/499: loss=4.967808036715215, w0=75.60000000000015, w1=12.139351360570384\n",
      "SubSGD iter. 330/499: loss=4.696416581836844, w0=74.90000000000015, w1=12.59833918468638\n",
      "SubSGD iter. 331/499: loss=4.576614289163684, w0=74.20000000000014, w1=12.524448961146508\n",
      "SubSGD iter. 332/499: loss=4.690536808298924, w0=74.90000000000015, w1=12.641078697004906\n",
      "SubSGD iter. 333/499: loss=4.504951520287131, w0=74.20000000000014, w1=13.169615348140377\n",
      "SubSGD iter. 334/499: loss=4.628600986076381, w0=74.90000000000015, w1=13.565192508406463\n",
      "SubSGD iter. 335/499: loss=4.883368071942839, w0=75.60000000000015, w1=12.688686464908443\n",
      "SubSGD iter. 336/499: loss=4.628797258366024, w0=74.90000000000015, w1=13.493482282668015\n",
      "SubSGD iter. 337/499: loss=4.697132486115872, w0=74.20000000000014, w1=11.951698987169758\n",
      "SubSGD iter. 338/499: loss=4.8303932576083, w0=74.90000000000015, w1=11.905061146767498\n",
      "SubSGD iter. 339/499: loss=4.684825251010143, w0=74.20000000000014, w1=12.00105648747563\n",
      "SubSGD iter. 340/499: loss=4.653277259563497, w0=73.50000000000014, w1=11.905503671915154\n",
      "SubSGD iter. 341/499: loss=4.705808228475413, w0=74.20000000000014, w1=11.917534523063235\n",
      "SubSGD iter. 342/499: loss=4.508255814927209, w0=73.50000000000014, w1=12.579283489684604\n",
      "SubSGD iter. 343/499: loss=4.495410104788286, w0=74.20000000000014, w1=13.417851247780067\n",
      "SubSGD iter. 344/499: loss=4.429416018725896, w0=73.50000000000014, w1=13.492625960486512\n",
      "SubSGD iter. 345/499: loss=4.483811303254942, w0=72.80000000000014, w1=14.320454192154338\n",
      "SubSGD iter. 346/499: loss=4.53227581331799, w0=72.10000000000014, w1=14.023605202957597\n",
      "SubSGD iter. 347/499: loss=4.441570217133222, w0=72.80000000000014, w1=13.773890306216686\n",
      "SubSGD iter. 348/499: loss=4.52591267555086, w0=72.10000000000014, w1=13.926487465893102\n",
      "SubSGD iter. 349/499: loss=4.6922450201668475, w0=71.40000000000013, w1=14.20268455109067\n",
      "SubSGD iter. 350/499: loss=4.6747570062429435, w0=72.10000000000014, w1=15.014686635484885\n",
      "SubSGD iter. 351/499: loss=4.438031657491181, w0=72.80000000000014, w1=13.571571215356096\n",
      "SubSGD iter. 352/499: loss=4.591056987395879, w0=73.50000000000014, w1=12.157682741458999\n",
      "SubSGD iter. 353/499: loss=4.848834574296557, w0=74.20000000000014, w1=11.430821051355116\n",
      "SubSGD iter. 354/499: loss=4.756070065510271, w0=73.50000000000014, w1=11.556961469643028\n",
      "SubSGD iter. 355/499: loss=4.788098094886473, w0=74.20000000000014, w1=11.622890057638111\n",
      "SubSGD iter. 356/499: loss=4.859614856600413, w0=74.90000000000015, w1=11.79079617775391\n",
      "SubSGD iter. 357/499: loss=4.690465890617343, w0=74.20000000000014, w1=11.978316173405322\n",
      "SubSGD iter. 358/499: loss=4.456943697150248, w0=73.50000000000014, w1=12.965627903812589\n",
      "SubSGD iter. 359/499: loss=4.509675692491724, w0=74.20000000000014, w1=13.975552635679657\n",
      "SubSGD iter. 360/499: loss=4.63185372126185, w0=74.90000000000015, w1=13.345147120841375\n",
      "SubSGD iter. 361/499: loss=4.494160731245676, w0=74.20000000000014, w1=13.527786688793219\n",
      "SubSGD iter. 362/499: loss=4.526777376139308, w0=73.50000000000014, w1=14.658939889181601\n",
      "SubSGD iter. 363/499: loss=4.605940987704828, w0=72.80000000000014, w1=15.035262549756183\n",
      "SubSGD iter. 364/499: loss=4.844505883510777, w0=72.10000000000014, w1=15.681802018519875\n",
      "SubSGD iter. 365/499: loss=4.853030022272925, w0=72.80000000000014, w1=15.93846509649201\n",
      "SubSGD iter. 366/499: loss=4.674300678916619, w0=72.10000000000014, w1=15.01253297055633\n",
      "SubSGD iter. 367/499: loss=4.9809855070944105, w0=71.40000000000013, w1=15.687716755020583\n",
      "SubSGD iter. 368/499: loss=4.566574841206568, w0=72.10000000000014, w1=14.37148853941657\n",
      "SubSGD iter. 369/499: loss=4.719174751568011, w0=72.80000000000014, w1=15.49512926017529\n",
      "SubSGD iter. 370/499: loss=4.597235595011742, w0=73.50000000000014, w1=15.026245487480937\n",
      "SubSGD iter. 371/499: loss=4.531298673276983, w0=74.20000000000014, w1=14.223181668080711\n",
      "SubSGD iter. 372/499: loss=4.494467228124015, w0=73.50000000000014, w1=14.444441025061794\n",
      "SubSGD iter. 373/499: loss=4.661995129630643, w0=74.20000000000014, w1=15.028301809691488\n",
      "SubSGD iter. 374/499: loss=4.432525928395922, w0=73.50000000000014, w1=13.725868764046751\n",
      "SubSGD iter. 375/499: loss=4.496638949034111, w0=72.80000000000014, w1=14.420804539381434\n",
      "SubSGD iter. 376/499: loss=4.436494198803007, w0=73.50000000000014, w1=13.242504931069655\n",
      "SubSGD iter. 377/499: loss=4.495157461968303, w0=74.20000000000014, w1=13.649382112832384\n",
      "SubSGD iter. 378/499: loss=4.629731356295256, w0=74.90000000000015, w1=13.680900214039315\n",
      "SubSGD iter. 379/499: loss=4.874204128384288, w0=75.60000000000015, w1=14.376809885444661\n",
      "SubSGD iter. 380/499: loss=4.741523342037463, w0=74.90000000000015, w1=14.788058009009337\n",
      "SubSGD iter. 381/499: loss=4.542406399465991, w0=74.20000000000014, w1=14.322070642100877\n",
      "SubSGD iter. 382/499: loss=4.48986459811271, w0=73.50000000000014, w1=14.410503991078814\n",
      "SubSGD iter. 383/499: loss=4.495143336099863, w0=74.20000000000014, w1=13.64866035128901\n",
      "SubSGD iter. 384/499: loss=4.464087255108336, w0=73.50000000000014, w1=12.89653833485368\n",
      "SubSGD iter. 385/499: loss=4.45476512289671, w0=72.80000000000014, w1=14.020266760435389\n",
      "SubSGD iter. 386/499: loss=4.435997914839861, w0=73.50000000000014, w1=13.252153568177777\n",
      "SubSGD iter. 387/499: loss=4.447551359118777, w0=72.80000000000014, w1=13.206142103555388\n",
      "SubSGD iter. 388/499: loss=4.676257455873465, w0=72.10000000000014, w1=12.159169082314511\n",
      "SubSGD iter. 389/499: loss=4.759007167504762, w0=71.40000000000013, w1=12.459444091544553\n",
      "SubSGD iter. 390/499: loss=4.51972066049599, w0=72.10000000000014, w1=13.792966813530748\n",
      "SubSGD iter. 391/499: loss=4.468569613318107, w0=72.80000000000014, w1=14.180448548495306\n",
      "SubSGD iter. 392/499: loss=4.527691810638412, w0=72.10000000000014, w1=13.956095778753772\n",
      "SubSGD iter. 393/499: loss=4.662597012372708, w0=71.40000000000013, w1=13.697958366786366\n",
      "SubSGD iter. 394/499: loss=4.878566113574492, w0=70.70000000000013, w1=13.776977521163953\n",
      "SubSGD iter. 395/499: loss=5.186380645418287, w0=70.00000000000013, w1=14.270964114558181\n",
      "SubSGD iter. 396/499: loss=5.128049434566502, w0=70.70000000000013, w1=15.496503898063523\n",
      "SubSGD iter. 397/499: loss=4.750194612296149, w0=71.40000000000013, w1=14.657760664989402\n",
      "SubSGD iter. 398/499: loss=5.080661837352488, w0=70.70000000000013, w1=15.2980105258396\n",
      "SubSGD iter. 399/499: loss=4.712492815284986, w0=71.40000000000013, w1=14.387651935323106\n",
      "SubSGD iter. 400/499: loss=4.60236510833347, w0=72.10000000000014, w1=14.626419367631362\n",
      "SubSGD iter. 401/499: loss=4.679529109485657, w0=71.40000000000013, w1=14.056417513848519\n",
      "SubSGD iter. 402/499: loss=4.875860020050031, w0=70.70000000000013, w1=13.548753822006915\n",
      "SubSGD iter. 403/499: loss=4.786579524139575, w0=71.40000000000013, w1=12.310094461057231\n",
      "SubSGD iter. 404/499: loss=4.540884834221079, w0=72.10000000000014, w1=13.009046773162162\n",
      "SubSGD iter. 405/499: loss=4.442451989892149, w0=72.80000000000014, w1=13.312925025315149\n",
      "SubSGD iter. 406/499: loss=4.694065991064407, w0=72.10000000000014, w1=12.083993394024871\n",
      "SubSGD iter. 407/499: loss=4.73441566121025, w0=71.40000000000013, w1=12.611936552177662\n",
      "SubSGD iter. 408/499: loss=4.542424368479366, w0=72.10000000000014, w1=12.992108969989927\n",
      "SubSGD iter. 409/499: loss=4.457842177067359, w0=72.80000000000014, w1=13.05448508754393\n",
      "SubSGD iter. 410/499: loss=4.4312856086607875, w0=73.50000000000014, w1=13.37753022081607\n",
      "SubSGD iter. 411/499: loss=4.445861835270689, w0=72.80000000000014, w1=13.87416397983698\n",
      "SubSGD iter. 412/499: loss=4.5156664307487775, w0=72.10000000000014, w1=13.595016458682684\n",
      "SubSGD iter. 413/499: loss=4.661884642677402, w0=71.40000000000013, w1=13.494222295978409\n",
      "SubSGD iter. 414/499: loss=4.566703653800394, w0=72.10000000000014, w1=12.769716270956655\n",
      "SubSGD iter. 415/499: loss=4.438098890136979, w0=72.80000000000014, w1=13.595941360389068\n",
      "SubSGD iter. 416/499: loss=4.524864708678938, w0=72.10000000000014, w1=13.907724181711306\n",
      "SubSGD iter. 417/499: loss=4.469194262953749, w0=72.80000000000014, w1=14.186701826240732\n",
      "SubSGD iter. 418/499: loss=4.492291691376871, w0=73.50000000000014, w1=12.680120228580586\n",
      "SubSGD iter. 419/499: loss=4.509057347554613, w0=74.20000000000014, w1=13.106571360838318\n",
      "SubSGD iter. 420/499: loss=4.4299669896344795, w0=73.50000000000014, w1=13.439267945458127\n",
      "SubSGD iter. 421/499: loss=4.505306601843897, w0=74.20000000000014, w1=13.163880436079408\n",
      "SubSGD iter. 422/499: loss=4.7090482523094, w0=74.90000000000015, w1=12.513054716190101\n",
      "SubSGD iter. 423/499: loss=4.945807046989771, w0=75.60000000000015, w1=12.260956356834296\n",
      "SubSGD iter. 424/499: loss=5.093214060163204, w0=76.30000000000015, w1=13.353052802337205\n",
      "SubSGD iter. 425/499: loss=5.411670527173687, w0=77.00000000000016, w1=13.721968454340951\n",
      "SubSGD iter. 426/499: loss=5.097495301892195, w0=76.30000000000015, w1=13.892242908403276\n",
      "SubSGD iter. 427/499: loss=4.837180875654782, w0=75.60000000000015, w1=13.913495601439045\n",
      "SubSGD iter. 428/499: loss=4.6879342457223565, w0=74.90000000000015, w1=14.449305111432663\n",
      "SubSGD iter. 429/499: loss=4.494992085669782, w0=74.20000000000014, w1=13.640799803184855\n",
      "SubSGD iter. 430/499: loss=4.454368964953104, w0=73.50000000000014, w1=12.992141752107777\n",
      "SubSGD iter. 431/499: loss=4.52462584576772, w0=74.20000000000014, w1=14.156185505299915\n",
      "SubSGD iter. 432/499: loss=4.432020963628669, w0=73.50000000000014, w1=13.709306744460157\n",
      "SubSGD iter. 433/499: loss=4.513877982815091, w0=74.20000000000014, w1=14.032525515720472\n",
      "SubSGD iter. 434/499: loss=4.671126506835238, w0=74.90000000000015, w1=14.314923052508977\n",
      "SubSGD iter. 435/499: loss=4.837428568598816, w0=75.60000000000015, w1=13.240060474545219\n",
      "SubSGD iter. 436/499: loss=4.631567927236632, w0=74.90000000000015, w1=13.354505550158537\n",
      "SubSGD iter. 437/499: loss=4.574277596525928, w0=74.20000000000014, w1=14.554317780437124\n",
      "SubSGD iter. 438/499: loss=4.6492458567736, w0=73.50000000000014, w1=15.24930779383558\n",
      "SubSGD iter. 439/499: loss=4.659899934033425, w0=74.20000000000014, w1=15.018616496304924\n",
      "SubSGD iter. 440/499: loss=4.935464122158501, w0=74.90000000000015, w1=15.620352674566279\n",
      "SubSGD iter. 441/499: loss=4.654918602608396, w0=74.20000000000014, w1=14.995392081903022\n",
      "SubSGD iter. 442/499: loss=4.7184314090933475, w0=74.90000000000015, w1=14.653703826947412\n",
      "SubSGD iter. 443/499: loss=4.494148276518567, w0=74.20000000000014, w1=13.551995682673457\n",
      "SubSGD iter. 444/499: loss=4.637040919726201, w0=74.90000000000015, w1=13.218342580575353\n",
      "SubSGD iter. 445/499: loss=4.591951104524081, w0=74.20000000000014, w1=12.433529662949919\n",
      "SubSGD iter. 446/499: loss=4.471854795527485, w0=73.50000000000014, w1=12.828939197670405\n",
      "SubSGD iter. 447/499: loss=4.5318489852024895, w0=74.20000000000014, w1=12.85372045928299\n",
      "SubSGD iter. 448/499: loss=4.429421737069774, w0=73.50000000000014, w1=13.545692663975371\n",
      "SubSGD iter. 449/499: loss=4.439845636855116, w0=72.80000000000014, w1=13.71671516702576\n",
      "SubSGD iter. 450/499: loss=4.62441225174624, w0=72.10000000000014, w1=12.407680092026663\n",
      "SubSGD iter. 451/499: loss=4.820947151253964, w0=71.40000000000013, w1=12.144904623487824\n",
      "SubSGD iter. 452/499: loss=4.895893733571787, w0=70.70000000000013, w1=13.058597854832323\n",
      "SubSGD iter. 453/499: loss=4.774381413961542, w0=71.40000000000013, w1=14.801496092647525\n",
      "SubSGD iter. 454/499: loss=4.884526943862557, w0=72.10000000000014, w1=15.815095008914497\n",
      "SubSGD iter. 455/499: loss=5.2623028937005945, w0=71.40000000000013, w1=16.543999460381805\n",
      "SubSGD iter. 456/499: loss=5.467411099864266, w0=70.70000000000013, w1=16.59858484484931\n",
      "SubSGD iter. 457/499: loss=5.264111673376591, w0=71.40000000000013, w1=16.548870358704477\n",
      "SubSGD iter. 458/499: loss=5.250292594551654, w0=72.10000000000014, w1=16.833230803387824\n",
      "SubSGD iter. 459/499: loss=5.325202213058933, w0=71.40000000000013, w1=16.710295824229895\n",
      "SubSGD iter. 460/499: loss=4.740702266274383, w0=72.10000000000014, w1=15.300222250570107\n",
      "SubSGD iter. 461/499: loss=4.9213521789841534, w0=71.40000000000013, w1=15.46805022871356\n",
      "SubSGD iter. 462/499: loss=4.830819152229709, w0=72.10000000000014, w1=15.634792240340609\n",
      "SubSGD iter. 463/499: loss=4.7506101009060435, w0=72.80000000000014, w1=15.60697371522698\n",
      "SubSGD iter. 464/499: loss=4.75433389724554, w0=73.50000000000014, w1=15.633829064167742\n",
      "SubSGD iter. 465/499: loss=5.115177141176142, w0=72.80000000000014, w1=16.655143170428566\n",
      "SubSGD iter. 466/499: loss=4.84577832652317, w0=72.10000000000014, w1=15.686114262324562\n",
      "SubSGD iter. 467/499: loss=4.710942918867992, w0=71.40000000000013, w1=14.37474799963837\n",
      "SubSGD iter. 468/499: loss=5.028254094638224, w0=70.70000000000013, w1=15.052952009111563\n",
      "SubSGD iter. 469/499: loss=5.172832640205364, w0=70.00000000000013, w1=14.104115079113337\n",
      "SubSGD iter. 470/499: loss=4.886466784674118, w0=70.70000000000013, w1=13.198776550746606\n",
      "SubSGD iter. 471/499: loss=4.680437801067824, w0=71.40000000000013, w1=13.078632454535493\n",
      "SubSGD iter. 472/499: loss=4.607873560717143, w0=72.10000000000014, w1=12.498464969458418\n",
      "SubSGD iter. 473/499: loss=4.481862571740175, w0=72.80000000000014, w1=12.821057408690793\n",
      "SubSGD iter. 474/499: loss=4.4394054384885155, w0=73.50000000000014, w1=13.190011001878654\n",
      "SubSGD iter. 475/499: loss=4.501279919305359, w0=74.20000000000014, w1=13.238613957470731\n",
      "SubSGD iter. 476/499: loss=4.561293272176523, w0=73.50000000000014, w1=12.296096462995168\n",
      "SubSGD iter. 477/499: loss=4.497953244447618, w0=74.20000000000014, w1=13.32193478005828\n",
      "SubSGD iter. 478/499: loss=4.6459636554176, w0=74.90000000000015, w1=14.04608269552238\n",
      "SubSGD iter. 479/499: loss=4.850052903651935, w0=75.60000000000015, w1=14.120505793890343\n",
      "SubSGD iter. 480/499: loss=4.701455699032568, w0=74.90000000000015, w1=14.544257631565229\n",
      "SubSGD iter. 481/499: loss=4.938880446031691, w0=75.60000000000015, w1=14.81982021972998\n",
      "SubSGD iter. 482/499: loss=5.228090710477658, w0=76.30000000000015, w1=15.01267276313661\n",
      "SubSGD iter. 483/499: loss=4.890644183878762, w0=75.60000000000015, w1=14.509755260179936\n",
      "SubSGD iter. 484/499: loss=4.775709063021548, w0=74.90000000000015, w1=14.965404616366184\n",
      "SubSGD iter. 485/499: loss=4.892152614783398, w0=75.60000000000015, w1=14.520894759764769\n",
      "SubSGD iter. 486/499: loss=4.9885358889284515, w0=74.90000000000015, w1=15.801767066354715\n",
      "SubSGD iter. 487/499: loss=4.865297529935381, w0=74.20000000000014, w1=15.8018110948539\n",
      "SubSGD iter. 488/499: loss=5.2949574966414605, w0=74.90000000000015, w1=16.690255771022905\n",
      "SubSGD iter. 489/499: loss=5.119150744428107, w0=75.60000000000015, w1=15.610689579236503\n",
      "SubSGD iter. 490/499: loss=4.759520693021907, w0=74.90000000000015, w1=14.884551107476014\n",
      "SubSGD iter. 491/499: loss=4.526051718552768, w0=74.20000000000014, w1=14.171115765901845\n",
      "SubSGD iter. 492/499: loss=4.445344541567693, w0=73.50000000000014, w1=13.97853590833324\n",
      "SubSGD iter. 493/499: loss=4.4385541455966155, w0=72.80000000000014, w1=13.46876623493319\n",
      "SubSGD iter. 494/499: loss=4.683769947325657, w0=72.10000000000014, w1=12.12700410653895\n",
      "SubSGD iter. 495/499: loss=4.796810415549211, w0=72.80000000000014, w1=11.464211826074331\n",
      "SubSGD iter. 496/499: loss=4.549693235924509, w0=72.10000000000014, w1=12.918081119330973\n",
      "SubSGD iter. 497/499: loss=4.608459213212727, w0=72.80000000000014, w1=12.126517225348678\n",
      "SubSGD iter. 498/499: loss=4.435021856601398, w0=73.50000000000014, w1=13.79415336231169\n",
      "SubSGD iter. 499/499: loss=4.63175279709743, w0=74.20000000000014, w1=14.88349120209384\n",
      "SubSGD: execution time=0.196 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c468615bfd41cab6dbc75bdb12d7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses, subsgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "state": {
    "d2b2c3aea192430e81437f33ba0b0e69": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "e4a6a7a70ccd42ddb112989c04f2ed3f": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
